# Comprehensive BirdNET-Pi Requirements Analysis & Dependency Graph
# This document serves as the complete roadmap for the BirdNET-Pi refactor.
# It is designed to be used by an automated agent with access to the MCP toolset.
---
features:
  - name: "Core Service Architecture"
    summary: "Establish the foundational service-oriented architecture, including directory structure, interfaces, and replacing legacy shell scripts."
    tags: [ "core-architecture" ]
    templates:
      - "Technical Approach"
    sections:
      - title: "Architecture Overview"
        format: "MARKDOWN"
        content: |
          ## Architecture Overview

          ### System Design
          The project was refactored from a collection of disparate shell scripts and PHP files into a modern, service-oriented architecture in Python. This design decouples components into logical layers: Managers (for business logic), Services (for low-level operations and external interactions), and Utilities. This separation of concerns makes the system more modular, testable, and maintainable.

          ### Key Components
          - **Managers**: High-level classes orchestrating specific domains (e.g., `AnalysisManager`, `DataManager`).
          - **Services**: Classes encapsulating interactions with external systems or low-level functions (e.g., `DatabaseService`, `NotificationService`).
          - **Utils**: General helper functions and utility classes (e.g., `FilePathResolver`).
          - **Python Wrappers**: Minimal Python entrypoint scripts that replace legacy shell scripts and call into the new manager/service layer.

          ### Design Patterns
          - **Service Layer Pattern**: Separates business logic from external-facing concerns.
          - **Dependency Injection**: Services and managers are provided with their dependencies upon initialization, promoting loose coupling and testability.

      - title: "Implementation Strategy"
        format: "MARKDOWN"
        content: |
          ## Implementation Strategy

          ### Implementation Phases
          1. **Phase 1: Foundation**: The core directory structure and interfaces were established.
          2. **Phase 2: Skeleton Implementation**: All manager and service classes were created with their basic method signatures.
          3. **Phase 3: Legacy Migration**: The logic from the old shell scripts was systematically moved into the new Python classes, and the old scripts were replaced with thin Python wrappers.
          4. **Phase 4: Integration Testing**: A suite of integration tests was developed to ensure all the new components worked together as expected.

    tasks:
      - title: "Establish Core Directory Structure"
        summary: "Create the foundational directory structure for the new Python application, including /src, /tests, /managers, /services, and /utils."
        status: "completed"
        priority: "critical"
        complexity: 1
      - title: "Define Core Service and Manager Interfaces"
        summary: "Define the abstract base classes and method signatures for all core services and managers to establish a clear architectural contract."
        status: "completed"
        priority: "critical"
        complexity: 2
        dependencies:
          - task_title: "Establish Core Directory Structure"
            type: "IS_BLOCKED_BY"
      - title: "Implement Core Utility Classes"
        summary: "Create foundational utility classes like FilePathResolver that are dependencies for other managers and services."
        status: "completed"
        priority: "critical"
        complexity: 2
        dependencies:
          - task_title: "Define Core Service and Manager Interfaces"
            type: "IS_BLOCKED_BY"
      - title: "Implement Initial Manager and Service Skeletons"
        summary: "Create the initial Python files and class skeletons for all managers and services based on the defined interfaces."
        status: "completed"
        priority: "critical"
        complexity: 3
        dependencies:
          - task_title: "Implement Core Utility Classes"
            type: "IS_BLOCKED_BY"
      - title: "Migrate Legacy Shell Scripts to Python Wrappers"
        summary: "Replace the logic of legacy shell scripts with Python entrypoint scripts that call methods on the new manager classes."
        status: "completed"
        priority: "critical"
        complexity: 3
        dependencies:
          - task_title: "Implement Initial Manager and Service Skeletons"
            type: "IS_BLOCKED_BY"
      - title: "Write Integration Tests for Core Architecture"
        summary: "Develop initial integration tests to ensure that the new managers, services, and Python wrappers interact correctly."
        status: "completed"
        priority: "critical"
        complexity: 2
        dependencies:
          - task_title: "Migrate Legacy Shell Scripts to Python Wrappers"
            type: "IS_BLOCKED_BY"

  - name: "Application Configuration System"
    summary: "Implement a robust, centralized configuration system using YAML files, replacing all legacy configuration methods."
    tags: [ "core-architecture", "system-administration" ]
    tasks:
      - title: "Define BirdNETConfig Dataclass Schema"
        summary: "Create the `BirdNETConfig` dataclass in `src/birdnetpi/models/` to serve as the schema for the YAML configuration file."
        status: "completed"
        priority: "high"
        complexity: 1
      - title: "Implement ConfigFileParser Utility"
        summary: "Create the `ConfigFileParser` utility in `src/birdnetpi/utils/` to load, parse, and validate the YAML file against the `BirdNETConfig` schema."
        status: "completed"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Define BirdNETConfig Dataclass Schema"
            type: "IS_BLOCKED_BY"
      - title: "Create Default YAML Configuration Template"
        summary: "Create the `birdnet_pi_config.yaml.template` file with default settings for new installations."
        status: "completed"
        priority: "high"
        complexity: 1
        dependencies:
          - task_title: "Define BirdNETConfig Dataclass Schema"
            type: "IS_BLOCKED_BY"
      - title: "Integrate ConfigService Throughout Application"
        summary: "Refactor all application components to load configuration from the new `ConfigFileParser` service, removing all legacy configuration methods."
        status: "completed"
        priority: "high"
        complexity: 3
        dependencies:
          - task_title: "Implement ConfigFileParser Utility"
            type: "IS_BLOCKED_BY"
      - title: "Write Unit Tests for Configuration System"
        summary: "Implement unit tests for the `ConfigFileParser` to ensure correct loading, parsing, and default value handling."
        status: "completed"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Integrate ConfigService Throughout Application"
            type: "IS_BLOCKED_BY"
      - title: "Run Pre-Commit Checks on Configuration Code"
        summary: "Run pre-commit hooks on all new and modified configuration-related modules."
        status: "completed"
        priority: "high"
        complexity: 1
        dependencies:
          - task_title: "Write Unit Tests for Configuration System"
            type: "IS_BLOCKED_BY"

  - name: "Database & Data Management"
    summary: "Implement the SQLite database, data models, and a web-based UI for database maintenance."
    tags: [ "core-architecture", "data" ]
    tasks:
      - title: "Define Database Models"
        summary: "Define the `Detection` and `AudioFile` SQLAlchemy models in `src/birdnetpi/models/database_models.py`."
        status: "completed"
        priority: "high"
        complexity: 1
      - title: "Implement DatabaseService"
        summary: "Create the `DatabaseService` to manage SQLite database connections and sessions."
        status: "completed"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Define Database Models"
            type: "IS_BLOCKED_BY"
      - title: "Implement DetectionManager"
        summary: "Create the `DetectionManager` to handle all business logic related to creating, retrieving, and deleting detection records."
        status: "completed"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Implement DatabaseService"
            type: "IS_BLOCKED_BY"
      - title: "Integrate SQLAdmin Interface"
        summary: "Integrate the `SQLAdmin` library into the FastAPI application to provide a web-based UI for database maintenance."
        status: "completed"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Implement DetectionManager"
            type: "IS_BLOCKED_BY"
      - title: "Write Unit Tests for Database Components"
        summary: "Implement unit tests for the `DatabaseService` and `DetectionManager` to ensure data integrity and correct query execution."
        status: "completed"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Integrate SQLAdmin Interface"
            type: "IS_BLOCKED_BY"
      - title: "Run Pre-Commit Checks on Database Code"
        summary: "Run pre-commit hooks on all new and modified database-related modules."
        status: "completed"
        priority: "high"
        complexity: 1
        dependencies:
          - task_title: "Write Unit Tests for Database Components"
            type: "IS_BLOCKED_BY"

  - name: "Web Application Foundation"
    summary: "Establish the core FastAPI web application, including routing, templating, and the main user-facing pages."
    tags: [ "core-architecture", "web-interface" ]
    tasks:
      - title: "Setup FastAPI Application and Uvicorn Server"
        summary: "Establish the main FastAPI application object in `src/birdnetpi/web/main.py` and configure Uvicorn as the ASGI server."
        status: "completed"
        priority: "critical"
        complexity: 2
        dependencies:
          - task_title: "Write Integration Tests for Core Architecture"
            type: "IS_BLOCKED_BY"
      - title: "Configure Jinja2 Templating and Static File Serving"
        summary: "Configure the FastAPI application to use the Jinja2 templating engine and serve static files (CSS, JS) from the `/static` directory."
        status: "completed"
        priority: "critical"
        complexity: 2
        dependencies:
          - task_title: "Setup FastAPI Application and Uvicorn Server"
            type: "IS_BLOCKED_BY"
      - title: "Create Base HTML Templates and CSS Structure"
        summary: "Develop the base Jinja2 templates (`base.html`) with common headers, footers, and navigation, along with the primary CSS stylesheet."
        status: "completed"
        priority: "critical"
        complexity: 2
        dependencies:
          - task_title: "Configure Jinja2 Templating and Static File Serving"
            type: "IS_BLOCKED_BY"
      - title: "Implement FastAPI Routers for Core Views"
        summary: "Define the APIRouters for the main application views, such as `views_router.py`, to organize URL endpoints."
        status: "completed"
        priority: "critical"
        complexity: 2
        dependencies:
          - task_title: "Create Base HTML Templates and CSS Structure"
            type: "IS_BLOCKED_BY"
      - title: "Develop 'Overview' and 'Todays Detections' Pages"
        summary: "Create the specific Jinja2 templates and backend router logic to fetch data from the appropriate managers and render the main user-facing pages."
        status: "completed"
        priority: "critical"
        complexity: 3
        dependencies:
          - task_title: "Implement FastAPI Routers for Core Views"
            type: "IS_BLOCKED_BY"
      - title: "Write Unit and Integration Tests for Web Interface"
        summary: "Develop pytest tests for the FastAPI routes and frontend components to ensure correctness."
        status: "completed"
        priority: "critical"
        complexity: 2
        dependencies:
          - task_title: "Develop 'Overview' and 'Todays Detections' Pages"
            type: "IS_BLOCKED_BY"
      - title: "Run Pre-Commit Checks on All Web Interface Code"
        summary: "Execute pre-commit hooks on all new and modified files in the `src/birdnetpi/web/` directory to ensure code quality."
        status: "completed"
        priority: "critical"
        complexity: 1
        dependencies:
          - task_title: "Write Unit and Integration Tests for Web Interface"
            type: "IS_BLOCKED_BY"

  - name: "Real-time Audio Capture"
    summary: "Develop a high-performance, pure Python audio pipeline to handle real-time audio capture and distribution."
    tags: [ "audio-pipeline" ]
    templates:
      - "Requirements Specification"
      - "Testing Strategy"
    sections:
      - title: "Must-Have Requirements"
        format: "MARKDOWN"
        content: |
          ## Must-Have Requirements

          ### Core Functionality
          1. **REQ-AUDIO-001**: Cross-Platform Audio Input
             - **Description**: The system must capture audio from a connected microphone or sound card using a pure Python library to ensure cross-platform compatibility.
             - **User Story**: As a developer, I need the audio capture to be handled in Python so that I can remove dependencies on external shell scripts like `arecord`, making the application more portable and easier to test.
             - **Acceptance Criteria**:
               - Given a compatible audio device is connected, the `AudioPipeline` service must be able to open an audio stream and read raw audio data.
               - The system must successfully capture audio on all target hardware platforms (Raspberry Pi 3B+, etc.).
             - **Priority**: Critical

          2. **REQ-AUDIO-002**: Publish-Subscribe Mechanism for Audio Distribution
             - **Description**: The audio pipeline must be able to distribute (fan out) the captured audio stream to multiple internal consumers (subscribers) simultaneously.
             - **User Story**: As an architect, I need a decoupled audio pipeline so that new consumers like a live spectrogram or a network streamer can be added in the future without modifying the core audio capture logic.
             - **Acceptance Criteria**:
               - The `AudioPipeline` must place captured audio chunks onto an in-memory queue.
               - Multiple subscriber processes must be able to consume from this queue concurrently.
             - **Priority**: Critical

          3. **REQ-AUDIO-003**: User-Selectable Audio Input Device
             - **Description**: The system must allow the user to select their desired audio input device from a list of available devices detected on the system.
             - **User Story**: As a user with multiple USB microphones, I want to choose which microphone BirdNET-Pi uses for recording so that I can select the best one for my environment.
             - **Acceptance Criteria**:
               - Given a user navigates to the settings page, a dropdown menu must be present listing all available audio input devices.
               - When a user selects a device and saves the configuration, the `AudioPipeline` service must restart and begin using the newly selected device for audio capture.
             - **Priority**: Critical

          ### Data Requirements
          - **Data Output**: Raw audio data chunks (e.g., NumPy arrays of PCM samples).
          - **Configuration**: A new setting in `birdnet_pi_config.yaml` to store the user's selected audio device.

      - title: "Constraints & Limitations"
        format: "MARKDOWN"
        content: |
          ## Constraints & Limitations

          ### Technical Constraints
          - **Technology Stack**: The implementation must use the `sounddevice` Python library for audio I/O.
          - **Inter-Process Communication**: For distributing audio between the capture process and the analysis process, a `multiprocessing.Queue` must be used.

          ### Performance Requirements
          - **Low Latency**: The audio capture and queuing process must have minimal latency to support real-time analysis.
          - **No Dropped Samples**: The pipeline must be able to handle the audio stream without dropping samples under normal operating conditions on the target hardware.

    tasks:
      - title: "Define AudioPipeline Service Interface"
        summary: "Create the abstract base class or interface for the audio service in `src/birdnetpi/services/audio_pipeline.py`."
        status: "pending"
        priority: "critical"
        complexity: 2
      - title: "Add Audio Device Setting to Configuration"
        summary: "Add a new field to the BirdNETConfig dataclass and the YAML file to store the selected audio device name or index."
        status: "pending"
        priority: "critical"
        complexity: 1
      - title: "Implement Audio Device Discovery"
        summary: "Create a method in a relevant manager that uses sounddevice.query_devices() to get a list of available input devices."
        status: "pending"
        priority: "critical"
        complexity: 2
        dependencies:
          - task_title: "Add Audio Device Setting to Configuration"
            type: "IS_BLOCKED_BY"
      - title: "Create API Endpoint for Audio Devices"
        summary: "Create a new authenticated FastAPI endpoint that exposes the list of available audio devices."
        status: "pending"
        priority: "critical"
        complexity: 2
        dependencies:
          - task_title: "Implement Audio Device Discovery"
            type: "IS_BLOCKED_BY"
      - title: "Create UI for Audio Device Selection"
        summary: "Develop a dropdown menu in the settings UI that populates with the list of devices from the API and allows the user to save their selection."
        status: "pending"
        priority: "critical"
        complexity: 3
        dependencies:
          - task_title: "Create API Endpoint for Audio Devices"
            type: "IS_BLOCKED_BY"
      - title: "Implement Sounddevice Audio Capture Module"
        summary: "Write the class responsible for capturing raw audio using the `sounddevice` library, reading the selected device from the configuration."
        status: "pending"
        priority: "critical"
        complexity: 3
        templates:
          - "Technical Approach"
        sections:
          - title: "Architecture Overview"
            format: "MARKDOWN"
            content: |
              ## Architecture Overview

              ### System Design
              This task will create the core audio capture component. It will be a class that initializes an audio stream using `sounddevice` in a separate process. The class will define a callback function that is executed by `sounddevice` whenever a new chunk of audio data is available. This callback will be responsible for placing the raw audio data onto a shared `multiprocessing.Queue`. The class must read the configured audio device from the `ConfigService` during initialization.

              ### Key Components
              - **`AudioCapture` Class**: The main class for this task.
              - **`sounddevice.InputStream`**: The underlying object that provides the audio data.
              - **`multiprocessing.Queue`**: The IPC mechanism for sending audio data to other processes.
              - **`ConfigService`**: The service providing the selected audio device.

              ### Data Flow
              `Audio Hardware → OS Audio Driver (ALSA) → PortAudio → sounddevice Library → AudioCapture Callback → multiprocessing.Queue`

              ### Technology Stack
              - **Language/Framework**: Python 3.11
              - **Libraries/Dependencies**: `sounddevice`, `numpy`
          - title: "Key Dependencies"
            format: "MARKDOWN"
            content: |
              ## Key Dependencies

              ### External Libraries
              | Library | Version | Purpose | Justification |
              |---------|---------|---------|---------------|
              | sounddevice | ~0.4.1 | Audio I/O | Cross-platform library with a simple callback-based API suitable for real-time streaming. |
              | numpy | ~1.23.0 | Numerical Data Handling | `sounddevice` provides audio data as NumPy arrays, which are efficient for processing. |

              ### System Dependencies
              - **PortAudio**: A system-level dependency (`libportaudio2`) required by `sounddevice`.
              - **ALSA**: The underlying audio driver architecture on Linux.

          - title: "Implementation Strategy"
            format: "MARKDOWN"
            content: |
              ## Implementation Strategy

              ### Implementation Phases
              1. **Phase 1: Basic Capture**
                 - **Goal**: Successfully open an audio stream from the configured device and print the shape of the incoming NumPy arrays.
                 - **Deliverables**: A script that can record 5 seconds of audio and confirm data is being received.

              2. **Phase 2: Callback and Queue Integration**
                 - **Goal**: Pass audio data from the `sounddevice` callback to a `multiprocessing.Queue`.
                 - **Deliverables**: A main process that can start the audio capture process and successfully retrieve audio chunks from the shared queue.

              ### Risk Mitigation
              - **Technical Risks**: Different audio hardware may have different channel counts or sample rates, causing configuration issues.
              - **Mitigation Strategy**: The implementation will include logic to query the capabilities of the selected audio device and will log a clear error message if the requested configuration (e.g., sample rate) is not supported.
        dependencies:
          - task_title: "Define AudioPipeline Service Interface"
            type: "IS_BLOCKED_BY"
          - task_title: "Create UI for Audio Device Selection"
            type: "IS_BLOCKED_BY"
      - title: "Create Unit Tests for Audio Capture Module"
        summary: "Write pytest tests in `tests/services/test_audio_pipeline.py` to mock and verify the audio capture logic."
        status: "pending"
        priority: "critical"
        complexity: 2
        dependencies:
          - task_title: "Implement Sounddevice Audio Capture Module"
            type: "IS_BLOCKED_BY"
      - title: "Implement In-Memory Publisher Queue"
        summary: "Implement the multiprocessing queue that will act as the central buffer for distributing audio chunks to subscribers."
        status: "pending"
        priority: "critical"
        complexity: 3
        dependencies:
          - task_title: "Implement Sounddevice Audio Capture Module"
            type: "IS_BLOCKED_BY"
      - title: "Create Unit Tests for Publisher Queue"
        summary: "Write pytest tests to verify the queue's functionality, including adding and removing items."
        status: "pending"
        priority: "critical"
        complexity: 2
        dependencies:
          - task_title: "Implement In-Memory Publisher Queue"
            type: "IS_BLOCKED_BY"
      - title: "Run Audio Pipeline Unit Tests"
        summary: "Execute all unit tests for the audio pipeline and ensure 100% pass rate."
        status: "pending"
        priority: "critical"
        complexity: 1
        dependencies:
          - task_title: "Create Unit Tests for Audio Capture Module"
            type: "IS_BLOCKED_BY"
          - task_title: "Create Unit Tests for Publisher Queue"
            type: "IS_BLOCKED_BY"
      - title: "Run Pre-Commit Checks on Audio Pipeline Modules"
        summary: "Run pre-commit hooks on all new and modified files in `src/birdnetpi/services/` and `tests/services/`."
        status: "pending"
        priority: "critical"
        complexity: 1
        dependencies:
          - task_title: "Run Audio Pipeline Unit Tests"
            type: "IS_BLOCKED_BY"

  - name: "Real-time Detection & Analysis"
    summary: "Implement the core analysis engine that subscribes to the audio stream and performs bird sound classification."
    tags: [ "audio-pipeline", "machine-learning" ]
    templates:
      - "Requirements Specification"
    sections:
      - title: "Must-Have Requirements"
        format: "MARKDOWN"
        content: |
          ## Must-Have Requirements

          ### Core Functionality
          1. **REQ-AN-001**: Real-time Audio Processing
             - **Description**: The system must be able to consume raw audio chunks from the audio pipeline and process them for machine learning inference.
             - **User Story**: As a user, I want the system to analyze the audio stream in real-time so that I can get immediate notifications of bird detections.
             - **Acceptance Criteria**:
               - Given the `AnalysisManager` receives an audio chunk from the `AudioPipeline`, it must successfully prepare the chunk for the ML model.
               - The processing of a standard audio chunk must complete within the performance budget on the target hardware.
             - **Priority**: Critical

          2. **REQ-AN-002**: BirdNET Model Inference
             - **Description**: The system must perform inference using the configured BirdNET machine learning model to identify bird species.
             - **User Story**: As a Hobbyist, I want the system to accurately identify the birds singing in my backyard.
             - **Acceptance Criteria**:
               - Given a processed audio chunk, the `AnalysisManager` must successfully run inference using the TFLite model.
               - For each species identified above the confidence threshold, a detection record must be created.
             - **Priority**: Critical

          3. **REQ-AN-003**: Detection Event Publishing
             - **Description**: After a successful detection, the system must publish an event to notify other parts of the application.
             - **User Story**: As a developer, I need the analysis service to publish detection events so that other services (like WebSockets and MQTT) can react to them.
             - **Acceptance Criteria**:
               - Given a new detection record is created, the `AnalysisManager` must publish a `new_detection` event via the `DetectionEventPublisher` (Blinker signal).
               - The event payload must contain the complete detection object.
             - **Priority**: Critical

          ### Data Requirements
          - **Data Input**: Raw audio chunks (NumPy arrays) from the `AudioPipeline`.
          - **Data Output**: `Detection` objects written to the SQLite database. `new_detection` events published internally.

      - title: "Constraints & Limitations"
        format: "MARKDOWN"
        content: |
          ## Constraints & Limitations

          ### Technical Constraints
          - **Technology Stack**: Must use the `tflite_runtime` Python library for inference with the provided BirdNET models.
          - **Model Format**: The initial implementation will only support the `.tflite` model format.

          ### Performance Requirements
          - **Throughput**: The analysis service must be able to process audio chunks faster than they are being produced by the audio pipeline to prevent a backlog.

    tasks:
      - title: "Implement Real-time Detection Engine"
        summary: "The analysis service will subscribe to the new audio pipeline, process audio chunks in real-time, and publish detection events."
        status: "pending"
        priority: "critical"
        complexity: 3
        templates:
          - "Task Implementation Workflow"
          - "Technical Approach"
        sections:
          - title: "Architecture Overview"
            format: "MARKDOWN"
            content: |
              ## Architecture Overview

              ### System Design
              The `AnalysisManager` will run in a dedicated process, acting as a consumer to the `multiprocessing.Queue` provided by the `AudioPipeline`. It will operate in an infinite loop, pulling audio chunks from the queue, preparing them, running inference with the TFLite model, and saving valid detections to the database. Upon saving, it will use the `DetectionEventPublisher` to broadcast the new detection to other services.

              ### Key Components
              - **`AnalysisManager`**: The core service for this feature.
              - **`multiprocessing.Queue`**: The input source for audio data.
              - **`tflite_runtime.Interpreter`**: The object used to run ML inference.
              - **`DetectionManager`**: The service used to persist detection records to the database.
              - **`DetectionEventPublisher`**: The service used to broadcast new detection events.

              ### Data Flow
              `AudioPipeline Queue → AnalysisManager (consumes chunk) → TFLite Interpreter (inference) → DetectionManager (saves to DB) → DetectionEventPublisher (publishes event)`

              ### Technology Stack
              - **Language/Framework**: Python 3.11
              - **Libraries/Dependencies**: `tflite_runtime`, `numpy`
          - title: "Key Dependencies"
            format: "MARKDOWN"
            content: |
              ## Key Dependencies

              ### External Libraries
              | Library | Version | Purpose | Justification |
              |---------|---------|---------|---------------|
              | tflite_runtime | ~2.5.0 | ML Inference | The official, lightweight TensorFlow Lite runtime for executing `.tflite` models. |
              | numpy | ~1.23.0 | Numerical Data Handling | Required for pre-processing audio data into the format expected by the model. |

              ### Internal Dependencies
              - **`AudioPipeline` Service**: Critically dependent on receiving audio chunks from this service via the queue.
              - **`DetectionManager` Service**: Depends on this service to write detection results to the database.
              - **`DetectionEventPublisher` Service**: Depends on this service to broadcast events.

          - title: "Implementation Strategy"
            format: "MARKDOWN"
            content: |
              ## Implementation Strategy

              ### Implementation Phases
              1. **Phase 1: Consumer Loop**
                 - **Goal**: Successfully consume audio chunks from the queue.
                 - **Deliverables**: A loop in `AnalysisManager` that can pull a NumPy array from the queue and log its shape.

              2. **Phase 2: Inference and Detection**
                 - **Goal**: Run the TFLite model and generate detection objects.
                 - **Deliverables**: The `AnalysisManager` can load the model, run inference on an audio chunk, and create a `Detection` object for results that exceed the confidence threshold.

              3. **Phase 3: Persistence and Publishing**
                 - **Goal**: Save detections and notify the system.
                 - **Deliverables**: The `AnalysisManager` successfully uses the `DetectionManager` to save the detection and the `DetectionEventPublisher` to broadcast the event.

              ### Risk Mitigation
              - **Technical Risks**: The TFLite model may have specific input shape or data type requirements that are not immediately obvious.
              - **Mitigation Strategy**: The first phase of implementation will include a dedicated step to inspect the model's input tensors and log their expected shape and dtype, ensuring the pre-processing logic is built correctly.
          - title: "Implementation Analysis"
            format: "MARKDOWN"
            content: |
              ## Implementation Analysis

              ### Task Context Review
              1. **Task Information Retrieval**: Review task details, including summary, priority, and dependencies on the `AudioPipeline`. The success criteria are defined in the feature's "Must-Have Requirements" (REQ-AN-001, REQ-AN-002, REQ-AN-003).
              2. **Related Context Analysis**: This task is the primary consumer of the `Real-time Audio Capture` feature and the primary producer for the `Live Dashboard & Visualization` and `MQTT Integration` features.
              3. **Technical Scope Assessment**:
                 - **Files to Modify**: `src/birdnetpi/managers/analysis_manager.py`
                 - **New Files**: `tests/managers/test_analysis_manager.py`
                 - **Dependencies**: `tflite_runtime`, `numpy`, `AudioPipeline` service, `DetectionManager` service.
                 - **Testing Strategy**: Unit tests for the analysis logic (mocking the model and audio input) and integration tests to verify the end-to-end flow from the audio queue to the event publisher.

              ### Implementation Planning
              1. **Break Down into Steps**:
                 - Step 1: Implement the main consumer loop in `AnalysisManager` to pull from the `multiprocessing.Queue`.
                 - Step 2: Add logic to load the TFLite model and its labels.
                 - Step 3: Implement audio pre-processing to convert the raw audio chunk into the format expected by the model.
                 - Step 4: Run inference and process the model's output.
                 - Step 5: For each valid result, use the `DetectionManager` to save it to the database.
                 - Step 6: After saving, use the `DetectionEventPublisher` to broadcast the new detection object.
          - title: "Step-by-Step Implementation"
            format: "MARKDOWN"
            content: |
              ## Step-by-Step Implementation

              ### Implementation Execution Process
              1. **Environment Setup**: Ensure the Python virtual environment is active and `tflite_runtime` is installed. Create a new git branch for this feature.
              2. **Incremental Implementation**:
                 a. **Code Changes**: Implement the consumer loop first. Then add the model loading, inference, and finally the database/event publishing logic.
                 b. **Immediate Verification**: After each step, run the application with a test audio source to ensure the new logic works as expected.
                 c. **Incremental Commit**: Commit after each logical step is completed (e.g., "feat: implement analysis consumer loop", "feat: add tflite inference logic").
          - title: "Testing & Validation"
            format: "MARKDOWN"
            content: |
              ## Testing & Validation

              ### Testing Strategy Implementation
              1. **Unit Testing**:
                 - Create `tests/managers/test_analysis_manager.py`.
                 - Write tests that provide a sample NumPy array (simulating an audio chunk) and mock the `tflite_runtime.Interpreter` to return a predictable output. Verify that the `DetectionManager` and `DetectionEventPublisher` are called with the correct data.
              2. **Integration Testing**:
                 - Write a test that starts the `AudioPipeline` and `AnalysisManager` in separate processes.
                 - Feed a known audio file into the pipeline and assert that a corresponding detection record is created in the test database.

              ### Validation Checklist
              - [ ] Core functionality works as specified.
              - [ ] All acceptance criteria in REQ-AN-001, REQ-AN-002, and REQ-AN-003 are met.
              - [ ] Unit tests pass with >80% coverage for the `AnalysisManager`.
              - [ ] Integration tests pass.
              - [ ] Code passes `pre-commit` checks.
        dependencies:
          - task_title: "Run Pre-Commit Checks on Audio Pipeline Modules"
            type: "IS_BLOCKED_BY"
      - title: "Implement Overlapping Chunk Strategy"
        summary: "Improve detection accuracy by processing partially overlapping audio chunks to avoid missing sounds at boundaries."
        status: "pending"
        priority: "medium"
        complexity: 3
        dependencies:
          - task_title: "Implement Real-time Detection Engine"
            type: "IS_BLOCKED_BY"
      - title: "Integrate SciPy and NumPy"
        summary: "Add SciPy and NumPy as project dependencies for signal processing."
        status: "pending"
        priority: "low"
        complexity: 1
      - title: "Define AudioFilter Framework"
        summary: "Create an abstract base class for audio filters in `src/birdnetpi/services/filters.py`."
        status: "pending"
        priority: "low"
        complexity: 1
        dependencies:
          - task_title: "Integrate SciPy and NumPy"
            type: "IS_BLOCKED_BY"
      - title: "Implement HighPassFilter"
        summary: "Create a `HighPassFilter` class that uses SciPy to apply a high-pass filter to an audio chunk."
        status: "pending"
        priority: "low"
        complexity: 2
        dependencies:
          - task_title: "Define AudioFilter Framework"
            type: "IS_BLOCKED_BY"
      - title: "Implement Sunrise/Sunset Trigger Service"
        summary: "Create a service that calculates sunrise and sunset times to determine when to apply day/night filters."
        status: "pending"
        priority: "low"
        complexity: 2
        dependencies:
          - task_title: "Define AudioFilter Framework"
            type: "IS_BLOCKED_BY"
      - title: "Integrate Filtering into Audio Pipeline"
        summary: "Modify the `AudioPipeline` service to apply the configured active filters to the audio stream."
        status: "pending"
        priority: "low"
        complexity: 2
        dependencies:
          - task_title: "Implement HighPassFilter"
            type: "IS_BLOCKED_BY"
          - task_title: "Implement Sunrise/Sunset Trigger Service"
            type: "IS_BLOCKED_BY"
      - title: "Write Unit Tests for Audio Filtering"
        summary: "Create unit tests for the filter classes and the trigger service."
        status: "pending"
        priority: "low"
        complexity: 2
        dependencies:
          - task_title: "Integrate Filtering into Audio Pipeline"
            type: "IS_BLOCKED_BY"
      - title: "Run Pre-Commit Checks on Filtering Modules"
        summary: "Run pre-commit hooks on all new filtering-related code."
        status: "pending"
        priority: "low"
        complexity: 1
        dependencies:
          - task_title: "Write Unit Tests for Audio Filtering"
            type: "IS_BLOCKED_BY"

  - name: "Live Dashboard & Visualization"
    summary: "Develop the primary real-time user interface components, including the live detection feed and spectrogram."
    tags: [ "web-interface", "ui-ux" ]
    templates:
      - "Requirements Specification"
    sections:
      - title: "Must-Have Requirements"
        format: "MARKDOWN"
        content: |
          ## Must-Have Requirements

          ### Core Functionality
          1. **REQ-LIVE-001**: Real-time Detection Feed
             - **Description**: The main dashboard must display new bird detections in real-time as they are processed by the analysis engine.
             - **User Story**: As a Hobbyist, I want to see new bird detections appear on the dashboard automatically so I can watch the activity unfold live without needing to refresh the page.
             - **Acceptance Criteria**:
               - Given the main dashboard is open, when a new detection occurs, it must be added to the top of the "Today's Detections" list within 2 seconds.
               - The update must occur via a WebSocket connection without a full page reload.
             - **Priority**: Critical

          2. **REQ-LIVE-002**: Live Audio Stream
             - **Description**: The user must be able to listen to the live audio being captured by the device directly from the web interface.
             - **User Story**: As a user, I want to listen to the live microphone feed so I can hear what the system is hearing in real-time.
             - **Acceptance Criteria**:
               - Given a user clicks the "Live Audio" button, an HTML5 audio player must appear and begin playing the live audio stream from the Audio Pipeline.
             - **Priority**: High

          3. **REQ-LIVE-003**: Streaming Spectrogram
             - **Description**: The web interface must display a real-time streaming spectrogram of the live audio feed.
             - **User Story**: As a Birder, I want to see a live spectrogram so I can visually identify bird calls and other sounds in the audio stream.
             - **Acceptance Criteria**:
               - Given the spectrogram view is open, a chart must be displayed that updates in real-time to show the frequency analysis of the current audio stream.
               - The spectrogram visualization must be synchronized with the live audio stream playback.
             - **Priority**: High

          ### Integration Requirements
          - **Internal System Integration**: This feature is critically dependent on the `AudioPipeline` for the live audio and the `DetectionEventPublisher` for real-time detection events. All real-time data will be pushed from the backend to the frontend via WebSockets.

      - title: "Constraints & Limitations"
        format: "MARKDOWN"
        content: |
          ## Constraints & Limitations

          ### Technical Constraints
          - **Technology Stack**: Must use FastAPI for WebSockets, Jinja2 for templating, and the JavaScript charting library selected in the "Species Statistics & Analysis" feature (e.g., Plotly.js).

          ### Performance Requirements
          - **Latency**: The end-to-end latency for a new detection appearing on the dashboard should be under 3 seconds.
          - **Resource Usage**: The spectrogram and live audio streaming must not significantly impact the performance of the core analysis services on an SBC.

    tasks:
      - title: "Implement Live UI Updates via WebSockets"
        summary: "The web interface will use WebSockets to listen for detection events and update the dashboard in real-time without requiring a page refresh."
        status: "pending"
        priority: "critical"
        complexity: 3
        dependencies:
          - task_title: "Implement Real-time Detection Engine"
            type: "IS_BLOCKED_BY"
      - title: "Create Live Audio Stream UI"
        summary: "Implement the frontend component to play the live audio stream from the new audio pipeline."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Run Pre-Commit Checks on Audio Pipeline Modules"
            type: "IS_BLOCKED_BY"
      - title: "Implement Backend Spectrogram Generation"
        summary: "Create a Python function to convert raw audio chunks into spectrogram data suitable for the chosen charting library."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Implement Frontend Data Fetching and Charting"
            type: "IS_BLOCKED_BY"
      - title: "Create Spectrogram WebSocket Endpoint"
        summary: "Implement a new FastAPI WebSocket endpoint (e.g., /ws/spectrogram) to stream spectrogram data to the frontend."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Implement Backend Spectrogram Generation"
            type: "IS_BLOCKED_BY"
      - title: "Integrate Spectrogram Generation with Audio Pipeline"
        summary: "Create a new subscriber to the AudioPipeline that generates and pushes spectrogram data to the WebSocket."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Create Spectrogram WebSocket Endpoint"
            type: "IS_BLOCKED_BY"
      - title: "Implement Frontend Spectrogram Client"
        summary: "Write the JavaScript client to connect to the WebSocket, receive spectrogram data, and update the chart in real-time."
        status: "pending"
        priority: "high"
        complexity: 3
        dependencies:
          - task_title: "Integrate Spectrogram Generation with Audio Pipeline"
            type: "IS_BLOCKED_BY"
      - title: "Write Integration Tests for Streaming Spectrogram"
        summary: "Create end-to-end tests to verify the entire spectrogram pipeline, from audio capture to frontend rendering."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Implement Frontend Spectrogram Client"
            type: "IS_BLOCKED_BY"
      - title: "Run Pre-Commit Checks on Spectrogram Code"
        summary: "Run pre-commit hooks on all new backend and frontend code related to the spectrogram feature."
        status: "pending"
        priority: "high"
        complexity: 1
        dependencies:
          - task_title: "Write Integration Tests for Streaming Spectrogram"
            type: "IS_BLOCKED_BY"

  - name: "Species Statistics & Analysis"
    summary: "A native data analysis page to replace the legacy Streamlit app, allowing users to explore historical detection data."
    tags: [ "web-interface", "data-visualization" ]
    templates:
      - "Requirements Specification"
    sections:
      - title: "Must-Have Requirements"
        format: "MARKDOWN"
        content: |
          ## Must-Have Requirements

          ### Core Functionality
          1. **REQ-STATS-001**: Interactive Date Range Selection
             - **Description**: The page must include a date range picker that allows users to filter all statistics and visualizations.
             - **User Story**: As a Birder, I want to be able to select a specific date range so that I can analyze my observations from a particular week, month, or season.
             - **Acceptance Criteria**:
               - Given the page is loaded, a date range picker is visible.
               - When a user selects a new date range, all charts and tables on the page must update to reflect the new range.
             - **Priority**: High

          2. **REQ-STATS-002**: Summary Statistics
             - **Description**: The page must display high-level summary statistics for the selected date range.
             - **User Story**: As a user, I want to see a quick summary of activity so I can understand the overall trends at a glance.
             - **Acceptance Criteria**:
               - The page must display "Total Detections" and "Unique Species" counts for the selected period.
             - **Priority**: High

          3. **REQ-STATS-003**: Data Tables and Charts
             - **Description**: The page must include several visualizations to explore the detection data.
             - **User Story**: As a Birder, I want to see charts and tables of my data so I can identify patterns in bird activity.
             - **Acceptance Criteria**:
               - A sortable table listing each species and its total detection count must be displayed.
               - A chart showing the distribution of detections by hour of the day must be displayed.
               - A heatmap showing species detected per day must be displayed.
             - **Priority**: High

          ### Integration Requirements
          - **Internal System Integration**: The page must fetch all data from new, authenticated FastAPI endpoints that call the `ReportingManager`.

      - title: "Nice-to-Have Features"
        format: "MARKDOWN"
        content: |
          ## Nice-to-Have Features

          ### User Experience Enhancements
          - **Data Export**: Provide a button to export the data from the "Detections by Species" table to a CSV file.
          - **Individual Species Drill-Down**: Allow users to click on a species in the table to view a more detailed page with a trend chart for that species over time.

      - title: "Constraints & Limitations"
        format: "MARKDOWN"
        content: |
          ## Constraints & Limitations

          ### Technical Constraints
          - **Technology Stack**: Must be implemented using FastAPI/Jinja2 for the backend and a JavaScript charting library (e.g., Plotly.js, ECharts) for the frontend. The legacy Streamlit dependency must be completely removed.

          ### Performance Requirements
          - **Query Performance**: All database queries generated by the `ReportingManager` for this page must be optimized to ensure the page loads quickly, even with a large detection history.

    tasks:
      - title: "Implement ReportingManager Data Methods"
        summary: "Create methods in the ReportingManager to fetch and process data for all required charts and tables (e.g., detections by species, by hour, by day)."
        status: "pending"
        priority: "high"
        complexity: 3
      - title: "Create FastAPI Endpoints for Stats Data"
        summary: "Create new authenticated FastAPI endpoints that expose the data from the ReportingManager."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Implement ReportingManager Data Methods"
            type: "IS_BLOCKED_BY"
      - title: "Design and Create Stats Page Template"
        summary: "Develop the Jinja2 template for the new 'Species Stats' page, including placeholders for charts and tables."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Create FastAPI Endpoints for Stats Data"
            type: "IS_BLOCKED_BY"
      - title: "Implement Frontend Data Fetching and Charting"
        summary: "Write the JavaScript to fetch data from the new endpoints and render the interactive charts and tables using a library like Plotly.js or ECharts."
        status: "pending"
        priority: "high"
        complexity: 3
        templates:
          - "Technical Approach"
        sections:
          - title: "Architecture Overview"
            format: "MARKDOWN"
            content: |
              ## Architecture Overview

              ### System Design
              The frontend for the statistics page will be a client-side application written in vanilla JavaScript. It will run within a Jinja2 template rendered by FastAPI. On page load, it will make asynchronous API calls to the backend to fetch the necessary data as JSON and then use a charting library to render the visualizations directly in the browser.

              ### Key Components
              - **`stats.js`**: A new JavaScript file to house all the client-side logic for this page.
              - **`ReportingManager`**: The existing backend manager that provides the data.
              - **FastAPI Endpoints**: The API routes that expose the `ReportingManager`'s data.
              - **Plotly.js/ECharts**: The chosen JavaScript library for rendering charts.

              ### Data Flow
              `User Action (Selects Date Range) → stats.js (API Call) → FastAPI Endpoint → ReportingManager (DB Query) → FastAPI (JSON Response) → stats.js (Renders Chart)`

              ### Technology Stack
              - **Language/Framework**: JavaScript (ES6+), FastAPI
              - **Libraries/Dependencies**: Plotly.js or ECharts
          - title: "Key Dependencies"
            format: "MARKDOWN"
            content: |
              ## Key Dependencies

              ### External Libraries
              | Library | Version | Purpose | Justification |
              |---------|---------|---------|---------------|
              | Plotly.js | latest | Interactive Charting | A powerful, well-documented, and versatile charting library that supports all the required chart types (tables, heatmaps, bar charts). |

              ### Internal Dependencies
              - **`ReportingManager`**: The frontend is critically dependent on the backend manager providing the correct data structures.
              - **FastAPI Endpoints**: Depends on the existence and correctness of the API endpoints for fetching stats data.

          - title: "Implementation Strategy"
            format: "MARKDOWN"
            content: |
              ## Implementation Strategy

              ### Implementation Phases
              1. **Phase 1: Data Fetching and Table Rendering**
                 - **Goal**: Ensure the frontend can successfully fetch data and display the main species table.
                 - **Deliverables**: A functional date-range picker that triggers an API call and populates a sortable HTML table with the results.

              2. **Phase 2: Chart Implementation**
                 - **Goal**: Render the graphical visualizations.
                 - **Deliverables**: Implementation of the "Detections by Hour" chart and the "Species by Day" heatmap using the chosen charting library.

              ### Technical Approach
              - **Code Organization**: All new JavaScript will be located in a dedicated `static/js/stats.js` file.
              - **Error Handling**: The JavaScript client will handle API errors gracefully, displaying a user-friendly message if data fails to load.
              - **Performance Considerations**: API calls will be debounced to prevent excessive requests while the user is interacting with the date picker.
        dependencies:
          - task_title: "Design and Create Stats Page Template"
            type: "IS_BLOCKED_BY"
      - title: "Write Unit Tests for ReportingManager Methods"
        summary: "Create pytest tests for the new data processing methods in the ReportingManager."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Implement Frontend Data Fetching and Charting"
            type: "IS_BLOCKED_BY"
      - title: "Write E2E Tests for Stats Page"
        summary: "Create end-to-end tests to verify the entire stats page functionality, from data fetching to chart rendering."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Write Unit Tests for ReportingManager Methods"
            type: "IS_BLOCKED_BY"
      - title: "Run Pre-Commit Checks on Stats Page Code"
        summary: "Run pre-commit hooks on all new code related to the statistics and analysis feature."
        status: "pending"
        priority: "high"
        complexity: 1
        dependencies:
          - task_title: "Write E2E Tests for Stats Page"
            type: "IS_BLOCKED_BY"

  - name: "Recordings Manager"
    summary: "A web-based interface for users to browse, play, download, and delete full-length audio recordings."
    tags: [ "web-interface", "data-management" ]
    templates:
      - "Requirements Specification"
    sections:
      - title: "Must-Have Requirements"
        format: "MARKDOWN"
        content: |
          ## Must-Have Requirements

          ### Core Functionality
          1. **REQ-REC-001**: List Recordings
             - **Description**: The system must provide a user interface that lists all available full-length audio recordings.
             - **User Story**: As a user, I want to see a list of all my recordings so I can easily find a specific one to review.
             - **Acceptance Criteria**:
               - Given a user navigates to the "Recordings" page, a table or list of all audio files from the recordings directory must be displayed.
               - Each item in the list must show the filename, date, and file size.
             - **Priority**: High

          2. **REQ-REC-002**: Play Recordings
             - **Description**: Users must be able to play back any audio recording directly in the web browser.
             - **User Story**: As a user, I want to listen to a recording directly in the UI so I can quickly verify its contents without downloading it.
             - **Acceptance Criteria**:
               - Given a user clicks a "Play" button next to a recording, an HTML5 audio player must appear and begin streaming the selected audio file.
             - **Priority**: High

          3. **REQ-REC-003**: Download and Delete Recordings
             - **Description**: Users must be able to download or delete individual recording files.
             - **User Story**: As an administrator, I want to be able to download recordings for archival purposes and delete old ones to manage disk space.
             - **Acceptance Criteria**:
               - Given a user clicks a "Download" button, the browser must initiate a download of the selected audio file.
               - Given a user clicks a "Delete" button, a confirmation dialog must appear. Upon confirmation, the selected audio file must be deleted from the disk.
             - **Priority**: High

          ### Integration Requirements
          - **Internal System Integration**: The UI must use authenticated FastAPI endpoints that call the `DataManager` to perform all file operations.

          ### Security Requirements
          - **Authentication**: Access to the Recordings Manager page and all associated API endpoints must be restricted to authenticated administrators.

      - title: "Nice-to-Have Features"
        format: "MARKDOWN"
        content: |
          ## Nice-to-Have Features

          ### User Experience Enhancements
          - **Bulk Operations**: Allow users to select multiple recordings to download as a single archive (`.zip`) or to delete in one action.
          - **Search and Filter**: Provide a search bar to filter the list of recordings by filename or date.

    tasks:
      - title: "Implement DataManager Methods for Recordings"
        summary: "Create methods in the DataManager to list audio files from the disk, provide file metadata, and handle file deletion."
        status: "pending"
        priority: "high"
        complexity: 2
      - title: "Create FastAPI Endpoints for Recordings"
        summary: "Create authenticated FastAPI endpoints to list, download, and delete recording files."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Implement DataManager Methods for Recordings"
            type: "IS_BLOCKED_BY"
      - title: "Design and Create Recordings Page Template"
        summary: "Develop the Jinja2 template for the new 'Recordings Manager' page, including a file browser interface."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Create FastAPI Endpoints for Recordings"
            type: "IS_BLOCKED_BY"
      - title: "Implement Frontend for Recordings Manager"
        summary: "Write the JavaScript to fetch the recording list from the API and implement the UI for playback, download, and deletion (with confirmation dialogs)."
        status: "pending"
        priority: "high"
        complexity: 3
        dependencies:
          - task_title: "Design and Create Recordings Page Template"
            type: "IS_BLOCKED_BY"
      - title: "Write Unit and Integration Tests for Recordings Manager"
        summary: "Create tests for the DataManager methods and the FastAPI endpoints to ensure correct file handling."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Implement Frontend for Recordings Manager"
            type: "IS_BLOCKED_BY"
      - title: "Run Pre-Commit Checks on Recordings Manager Code"
        summary: "Run pre-commit hooks on all new code related to the Recordings Manager feature."
        status: "pending"
        priority: "high"
        complexity: 1
        dependencies:
          - task_title: "Write Unit and Integration Tests for Recordings Manager"
            type: "IS_BLOCKED_BY"

  - name: "System Administration UI"
    summary: "Web-based interfaces for administrators to manage and monitor the system."
    tags: [ "system-administration", "web-interface" ]
    templates:
      - "Requirements Specification"
    sections:
      - title: "Must-Have Requirements"
        format: "MARKDOWN"
        content: |
          ## Must-Have Requirements

          ### Core Functionality
          1. **REQ-ADMIN-001**: Structured Logging
             - **Description**: The system must implement a centralized logging service that produces structured JSON logs to provide detailed visibility into the application's behavior.
             - **User Story**: As an administrator, I need structured, environment-aware logs so that I can effectively monitor system health and debug issues whether the application is running in Docker or on a bare-metal SBC.
             - **Acceptance Criteria**:
               - Given the application is running, all log output must be in a consistent JSON format.
               - Given the application is running in a Docker container, logs must be directed to `stdout`.
               - Given the application is running on a bare-metal system with `systemd`, logs must be directed to `journald`.
             - **Priority**: Critical

          2. **REQ-ADMIN-002**: Log Viewer Page
             - **Description**: The web interface must provide a dedicated, authenticated page for viewing system logs.
             - **User Story**: As an administrator, I want to be able to view the system logs directly in the web UI so that I don't have to SSH into the device for basic troubleshooting.
             - **Acceptance Criteria**:
               - An authenticated user must be able to access a `/logs` page.
               - The page must display log entries in a readable format.
               - The page must provide controls to filter logs by service and log level.
             - **Priority**: High

          3. **REQ-ADMIN-003**: Configuration Editor Page
             - **Description**: The web interface must provide a dedicated, authenticated page for viewing and editing the main `birdnet_pi_config.yaml` file.
             - **User Story**: As an administrator, I want to edit the main configuration file from the web UI so that I can make quick changes without needing command-line access.
             - **Acceptance Criteria**:
               - An authenticated user must be able to view the contents of the YAML configuration file.
               - The user must be able to save changes to the file, with validation to prevent syntax errors.
             - **Priority**: High

          4. **REQ-ADMIN-004**: Update Process Page
             - **Description**: The web interface must provide a UI for initiating system updates.
             - **User Story**: As an administrator, I want to be able to update the application from the web UI so that I can easily keep my system up to date.
             - **Acceptance Criteria**:
               - An authenticated user must be able to trigger the update process from a button in the UI.
               - The UI must provide real-time feedback on the status of the update process.
             - **Priority**: High

          5. **REQ-ADMIN-005**: Species List Manager Page
             - **Description**: The web interface must provide a UI for managing the include and exclude species lists.
             - **User Story**: As a user, I want to manage my species lists from the web UI so that I can easily customize which birds are reported.
             - **Acceptance Criteria**:
               - An authenticated user must be able to view the current species in the include and exclude lists.
               - The user must be able to add or remove species from each list.
             - **Priority**: High

          ### Integration Requirements
          - **Internal System Integration**: The UI components must interact with their corresponding backend managers (`LogManager`, `ConfigService`, `UpdateManager`, `SpeciesListUtils`) via authenticated FastAPI endpoints.

          ### Security Requirements
          - **Authentication**: All pages and API endpoints related to system administration must require administrator authentication.

      - title: "Nice-to-Have Features"
        format: "MARKDOWN"
        content: |
          ## Nice-to-Have Features

          ### User Experience Enhancements
          - **Configuration Validation**: Provide real-time validation and hints in the configuration editor UI.
          - **Log Highlighting**: Color-code logs in the Log Viewer based on log level (e.g., red for errors).

      - title: "Constraints & Limitations"
        format: "MARKDOWN"
        content: |
          ## Constraints & Limitations

          ### Technical Constraints
          - **Web Terminal**: The replacement for the `gotty` web terminal is a lower priority and may not be included in the initial implementation of the admin UI.

    tasks:
      - title: "Implement Environment-Aware Structured Logging"
        summary: "Implement a centralized logging system that produces structured JSON logs, automatically directing output to stdout (Docker) or journald (bare-metal)."
        status: "pending"
        priority: "critical"
        complexity: 3
      - title: "Create Log Viewer Page"
        summary: "Create a dedicated, authenticated page to view system logs, with filtering capabilities."
        status: "pending"
        priority: "high"
        complexity: 3
        dependencies:
          - task_title: "Implement Environment-Aware Structured Logging"
            type: "IS_BLOCKED_BY"
      - title: "Create Configuration Editor Page"
        summary: "Create a dedicated, authenticated page to view and edit the main birdnet_pi_config.yaml file."
        status: "pending"
        priority: "high"
        complexity: 3
        dependencies:
          - task_title: "Implement Environment-Aware Structured Logging"
            type: "IS_BLOCKED_BY"
      - title: "Create Update Process UI"
        summary: "Create a UI in the admin section to trigger system updates and display real-time progress."
        status: "pending"
        priority: "high"
        complexity: 3
        dependencies:
          - task_title: "Implement Environment-Aware Structured Logging"
            type: "IS_BLOCKED_BY"
      - title: "Create Species List Manager Page"
        summary: "Create an authenticated page to manage the include/exclude species lists."
        status: "pending"
        priority: "high"
        complexity: 3
        dependencies:
          - task_title: "Implement Environment-Aware Structured Logging"
            type: "IS_BLOCKED_BY"
      - title: "Implement Web Terminal"
        summary: "Replace the legacy gotty web terminal with a modern, integrated Python-based solution."
        status: "pending"
        priority: "low"
        complexity: 3
        dependencies:
          - task_title: "Implement Environment-Aware Structured Logging"
            type: "IS_BLOCKED_BY"

  - name: "Dynamic Geolocation"
    summary: "Implement support for dynamic location tracking for mobile and field use cases."
    tags: [ "field-mode" ]
    templates:
      - "Requirements Specification"
    sections:
      - title: "Must-Have Requirements"
        format: "MARKDOWN"
        content: |
          ## Must-Have Requirements

          ### Core Functionality
          1. **REQ-GEO-001**: GPSD Integration for Real-time Location
             - **Description**: The system must be able to connect to a `gpsd` daemon running on the host to retrieve real-time latitude and longitude data.
             - **User Story**: As a Field User, I want the device to automatically capture my GPS coordinates with each detection so that my data is accurately geotagged without manual input.
             - **Acceptance Criteria**:
               - Given the system is running and a `gpsd`-compatible GPS device is connected, when a bird is detected, then the detection record in the database must include the latitude and longitude provided by `gpsd`.
               - Given `gpsd` is not available or not providing a fix, when a bird is detected, then the location fields in the detection record must be left null.
             - **Priority**: Critical

          2. **REQ-GEO-002**: Recording Sessions and Retroactive Geotagging
             - **Description**: The system must support the concept of "Recording Sessions." Users must be able to manually assign a single location to an entire session after it has been completed.
             - **User Story**: As a Field User, I want to be able to assign a location to a whole batch of recordings later if I forgot to turn on my GPS, so that my data isn't missing location information.
             - **Acceptance Criteria**:
               - Given a user is viewing a list of past recording sessions, when they select a session, then they must be presented with an option to set a location for all detections within that session.
               - Given a user sets a location for a session, then all detection records associated with that session's audio files must have their latitude and longitude fields updated.
             - **Priority**: Critical

          ### Data Requirements
          - **Data Input**: Latitude and Longitude floating-point numbers from `gpsd`. User-selected location from a map interface.
          - **Data Storage**: `latitude` and `longitude` fields in the `detections` table must be nullable floats. A `session_id` field must be added to the `audio_files` table.

          ### User Interface Requirements
          - **Recording Sessions UI**: A new page in the web interface that lists distinct recording sessions.
          - **Map Interface**: A map-based UI (e.g., using Leaflet.js) that allows a user to drop a pin or search for a location to set a session's coordinates.

      - title: "Nice-to-Have Features"
        format: "MARKDOWN"
        content: |
          ## Nice-to-Have Features

          ### User Experience Enhancements
          - **Live GPS Status Indicator**: A small icon in the UI that shows the current status of the GPS connection (e.g., no signal, acquiring fix, locked).
          - **Session Naming**: Allow users to give custom names to their recording sessions for easier identification.

      - title: "Constraints & Limitations"
        format: "MARKDOWN"
        content: |
          ## Constraints & Limitations

          ### Technical Constraints
          - **System Dependency**: The feature is dependent on the `gpsd` and `gpsd-clients` packages being installed and running on the host operating system.
          - **Hardware**: Requires a user-provided USB or serial GPS device compatible with `gpsd`.

          ### Performance Requirements
          - **GPS Polling**: Polling `gpsd` for location data must not introduce significant latency to the audio analysis pipeline.

    tasks:
      - title: "Research and Select GPSD Integration Library"
        summary: "Investigate and choose a Python library for interacting with the gpsd daemon to retrieve real-time location data."
        status: "pending"
        priority: "high"
        complexity: 2
        templates:
          - "Technical Approach"
      - title: "Implement GeolocationService"
        summary: "Create a new service `GeolocationService` that connects to gpsd and provides a method to get the current coordinates."
        status: "pending"
        priority: "high"
        complexity: 3
        dependencies:
          - task_title: "Research and Select GPSD Integration Library"
            type: "IS_BLOCKED_BY"
      - title: "Integrate Geolocation into DetectionManager"
        summary: "Modify the `DetectionManager` to call the `GeolocationService` and store the latitude and longitude with each new detection record."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Implement GeolocationService"
            type: "IS_BLOCKED_BY"
      - title: "Implement 'Recording Sessions' Concept"
        summary: "Add a `session_id` to the `AudioFile` model and create a mechanism to start and stop recording sessions."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Integrate Geolocation into DetectionManager"
            type: "IS_BLOCKED_BY"
      - title: "Create UI for Retroactive Geotagging"
        summary: "Develop a UI page where users can view past recording sessions and assign a location to them from a map interface."
        status: "pending"
        priority: "high"
        complexity: 3
        dependencies:
          - task_title: "Implement 'Recording Sessions' Concept"
            type: "IS_BLOCKED_BY"
      - title: "Write Unit and Integration Tests for Geolocation"
        summary: "Create tests for the `GeolocationService` and verify that detections are correctly tagged with location data."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Create UI for Retroactive Geotagging"
            type: "IS_BLOCKED_BY"
      - title: "Run Pre-Commit Checks on Geolocation Code"
        summary: "Run pre-commit hooks on all new geolocation-related modules."
        status: "pending"
        priority: "high"
        complexity: 1
        dependencies:
          - task_title: "Write Unit and Integration Tests for Geolocation"
            type: "IS_BLOCKED_BY"

  - name: "Hardware Status Monitoring"
    summary: "Implement active monitoring of connected hardware, such as audio input devices."
    tags: [ "field-mode", "system-administration" ]
    templates:
      - "Requirements Specification"
    sections:
      - title: "Must-Have Requirements"
        format: "MARKDOWN"
        content: |
          ## Must-Have Requirements

          ### Core Functionality
          1. **REQ-HSM-001**: Audio Device Disconnection Detection
             - **Description**: The system must actively monitor the connection status of the selected audio input device (microphone/soundcard).
             - **User Story**: As a Field User, I need to be immediately alerted if my microphone gets unplugged so that I don't unknowingly record silence and lose valuable data.
             - **Acceptance Criteria**:
               - Given a recording is in progress with a connected audio device, when the device is physically disconnected, then a "disconnected" event is triggered within the application.
               - Given the application starts without the configured audio device being present, then a "disconnected" event is triggered.
             - **Priority**: Critical

          2. **REQ-HSM-002**: User-Facing Notification
             - **Description**: When an audio device disconnection is detected, a clear and persistent visual notification must be presented to the user in the web interface.
             - **User Story**: As a Field User, I want a clear, unmissable warning on my screen when the microphone is not working so I can immediately fix the connection.
             - **Acceptance Criteria**:
               - Given a "disconnected" event is triggered, when a user is viewing the web interface, then a prominent status indicator (e.g., a red, flashing icon in the navbar) must appear.
               - Given the audio device is reconnected and the system detects it, then the visual warning must be removed.
             - **Priority**: Critical

          ### Integration Requirements
          - **API Requirements**: A WebSocket endpoint must be available for the frontend to receive real-time hardware status updates.
          - **Internal System Integration**: The monitoring logic must be integrated directly into the new pure Python Audio Pipeline. The pipeline will be the source of truth for the audio device's status.

          ### User Interface Requirements
          - **User Experience**: The status indicator must be placed in a globally visible area, such as the main navigation bar, and use color (red for error) and possibly an icon to clearly communicate the status.
          - **Accessibility**: The indicator should be accessible to screen readers, providing a text-based alert (e.g., "Warning: Audio device disconnected").

      - title: "Nice-to-Have Features"
        format: "MARKDOWN"
        content: |
          ## Nice-to-Have Features

          ### User Experience Enhancements
          - **Audible Alerts**: Play an audible warning sound in the browser in addition to the visual indicator to alert users who may not be looking at the screen.
          - **Periodic Re-check**: If a device is disconnected, the system could periodically attempt to re-establish the connection automatically and clear the warning if successful.

      - title: "Constraints & Limitations"
        format: "MARKDOWN"
        content: |
          ## Constraints & Limitations

          ### Technical Constraints
          - **Technology Stack**: The implementation must use the existing Python `sounddevice` library for audio I/O and FastAPI for WebSockets.
          - **Detection Method**: Relies on the `sounddevice` library and the underlying OS audio driver (PortAudio/ALSA) to raise an exception or error code upon device failure. The detection is reactive, not proactive.

          ### Performance Requirements
          - **Resource Usage**: The monitoring process must have a negligible impact on CPU and memory usage, as it will run continuously.

          ### Security Requirements
          - **Authentication**: The WebSocket endpoint for status updates should not require authentication, as it provides non-sensitive system status information.

    tasks:
      - title: "Integrate Hardware Monitoring into AudioPipeline"
        summary: "Add logic to the `AudioPipeline` service to detect errors during audio stream reading, which indicate a device disconnection."
        status: "pending"
        priority: "high"
        complexity: 2
        templates:
          - "Technical Approach"
        sections:
          - title: "Architecture Overview"
            format: "MARKDOWN"
            content: |
              ## Architecture Overview

              ### System Design
              The hardware monitoring will be integrated directly into the `AudioPipeline` service. This service is the only component that directly interacts with the audio hardware, making it the natural place to detect connection issues. The detection will be reactive, based on exceptions raised by the `sounddevice` library during stream operations.

              ### Key Components
              - **`AudioPipeline` Service**: The core audio capture service. It will be modified to include error handling for device disconnections.
              - **`sounddevice` Library**: The underlying audio library that provides the error signals.
              - **`HardwareStatusPublisher`**: A new component (or an extension of an existing publisher) that will broadcast the status change event.

              ### Design Patterns
              - **Observer Pattern**: The `AudioPipeline` will act as the subject, and the `HardwareStatusPublisher` will be an observer that reacts to state changes (device errors).

              ### Data Flow
              `Audio Device → sounddevice Library → AudioPipeline Service (Exception Caught) → HardwareStatusPublisher → WebSocket → Frontend UI`

              ### Integration Points
              - **Internal System**: The `AudioPipeline` service is the primary integration point.
              - **External System/Service**: None.

              ### Technology Stack
              - **Language/Framework**: Python 3.11
              - **Libraries/Dependencies**: `sounddevice`, `blinker` (for internal signaling)
          - title: "Key Dependencies"
            format: "MARKDOWN"
            content: |
              ## Key Dependencies

              ### External Libraries
              | Library | Version | Purpose | Justification |
              |---------|---------|---------|---------------|
              | sounddevice | ~0.4.1 | Audio I/O | Core library for interacting with PortAudio/ALSA. |
              | blinker | ~1.4 | In-process signaling | Used for decoupling the event publishing from the audio pipeline. |

              ### Internal Dependencies
              - **`AudioPipeline` Service**: This task directly modifies this existing service.

          - title: "Implementation Strategy"
            format: "MARKDOWN"
            content: |
              ## Implementation Strategy

              ### Implementation Phases
              1. **Phase 1: Error Detection**
                 - **Goal**: Reliably detect audio device disconnection.
                 - **Deliverables**: A try-except block within the `AudioPipeline`'s main audio reading loop that specifically catches exceptions related to device errors (e.g., `PortAudioError`).
                 - **Duration**: 1 story point.
                 - **Dependencies**: A functional `AudioPipeline` service.

              2. **Phase 2: Event Publishing**
                 - **Goal**: Broadcast the hardware status change to the rest of the application.
                 - **Deliverables**: When an error is caught, the `AudioPipeline` will call the `HardwareStatusPublisher` to send a "disconnected" event. It will also send a "connected" event when the stream is successfully (re)started.
                 - **Duration**: 1 story point.
                 - **Dependencies**: Phase 1.

              ### Technical Approach
              - **Code Organization**: All new logic will be contained within the `AudioPipeline` service in `src/birdnetpi/services/audio_pipeline.py`.
              - **Error Handling**: The core of this task is robust error handling. The implementation must specifically identify the exception types thrown by `sounddevice` on device failure and handle them gracefully without crashing the service.
              - **Logging and Monitoring**: The service will log a critical error message using the structured logger when a device disconnects and an info message when it reconnects.

              ### Risk Mitigation
              - **Technical Risks**: The specific exception raised by `sounddevice` may vary across different operating systems or hardware.
              - **Mitigation Strategy**: The implementation will include a broad exception handler initially, with detailed logging to capture the exact error types encountered on the target hardware (RPi 3B+, etc.). This will allow for refinement in subsequent patches.

              ### Alternative Approaches Considered
              - **Alternative 1**: A separate monitoring process that periodically polls the list of connected audio devices.
              - **Why Rejected**: Polling is less efficient and less "real-time" than reactive error handling. It adds unnecessary complexity and another process to manage. The most reliable way to know if a device is working is to try and use it.
        dependencies:
          - task_title: "Run Pre-Commit Checks on Audio Pipeline Modules"
            type: "IS_BLOCKED_BY"
      - title: "Implement Hardware Status Publisher"
        summary: "Create a new Blinker signal or WebSocket publisher that broadcasts hardware status events (e.g., 'audio_device_disconnected')."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Integrate Hardware Monitoring into AudioPipeline"
            type: "IS_BLOCKED_BY"
      - title: "Create Frontend Hardware Status Indicator"
        summary: "Implement a UI component (e.g., a status icon in the navbar) that listens for hardware status events and displays a clear visual warning to the user."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Implement Hardware Status Publisher"
            type: "IS_BLOCKED_BY"
      - title: "Write Integration Tests for Hardware Monitoring"
        summary: "Create tests that simulate a device disconnection and verify that the correct event is published and the UI is updated."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Create Frontend Hardware Status Indicator"
            type: "IS_BLOCKED_BY"
      - title: "Run Pre-Commit Checks on Hardware Monitoring Code"
        summary: "Run pre-commit hooks on all new hardware monitoring-related code."
        status: "pending"
        priority: "high"
        complexity: 1
        dependencies:
          - task_title: "Write Integration Tests for Hardware Monitoring"
            type: "IS_BLOCKED_BY"

  - name: "Simplified Field Mode UI"
    summary: "Design and implement a user interface optimized for small screens and mobile use."
    tags: [ "field-mode", "ui-ux" ]
    templates:
      - "Requirements Specification"
    sections:
      - title: "Must-Have Requirements"
        format: "MARKDOWN"
        content: |
          ## Must-Have Requirements

          ### Core Functionality
          1. **REQ-FMUI-001**: High-Contrast, Minimalist Layout
             - **Description**: The system must provide a dedicated web page with a UI theme optimized for high visibility on small screens, including monochrome OLED displays.
             - **User Story**: As a Field User, I need a simple, high-contrast display so that I can easily read detection information at a glance while in a vehicle or bright sunlight.
             - **Acceptance Criteria**:
               - Given a user navigates to the `/field` endpoint, the page must render using a CSS theme with a black background, large white/monochrome fonts, and touch-friendly button sizes.
               - Given a new detection is received via WebSocket, it must be added to the top of a simple, auto-scrolling list on the page.
             - **Priority**: Critical

          ### Data Requirements
          - **Data Input**: Real-time detection events received from the WebSocket. Each event must contain the species name and confidence score.

          ### User Interface Requirements
          - **User Experience**: The UI must be extremely simple, displaying only a list of detections (e.g., "American Robin - 0.88"). It should require zero user interaction to be useful.
          - **Accessibility**: The high-contrast theme and large font sizes are the primary accessibility requirements.
          - **Responsive Design**: The layout must be fluid and function correctly on screens with a width as small as 320 pixels.

      - title: "Nice-to-Have Features"
        format: "MARKDOWN"
        content: |
          ## Nice-to-Have Features

          ### User Experience Enhancements
          - **Confidence Threshold Slider**: Allow the user to adjust the minimum confidence score for a detection to be displayed on the field UI in real-time.
          - **Tap-to-Hear**: Allow a user to tap on a detection in the list to play the associated audio clip.

      - title: "Constraints & Limitations"
        format: "MARKDOWN"
        content: |
          ## Constraints & Limitations

          ### Technical Constraints
          - **Technology Stack**: Must be implemented using the existing FastAPI/Jinja2 backend and standard HTML/CSS/JavaScript for the frontend. No new frontend frameworks should be introduced.

          ### Performance Requirements
          - **Resource Usage**: The page must be lightweight and have minimal impact on the performance of the core audio analysis services running on the SBC.

    tasks:
      - title: "Design High-Contrast UI Theme"
        summary: "Create a new CSS theme specifically for field mode, focusing on high contrast, large fonts, and touch-friendly targets."
        status: "pending"
        priority: "high"
        complexity: 2
      - title: "Create Field Mode Jinja2 Template"
        summary: "Develop a new Jinja2 template that presents a simple, auto-scrolling list of recent detections and their confidence scores."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Design High-Contrast UI Theme"
            type: "IS_BLOCKED_BY"
      - title: "Implement Field Mode FastAPI Route"
        summary: "Create a new FastAPI route (e.g., /field) that renders the new field mode template."
        status: "pending"
        priority: "high"
        complexity: 1
        dependencies:
          - task_title: "Create Field Mode Jinja2 Template"
            type: "IS_BLOCKED_BY"
      - title: "Integrate Field Mode with Live UI Updates"
        summary: "Ensure the field mode page correctly connects to the WebSocket and displays new detections in real-time."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Implement Field Mode FastAPI Route"
            type: "IS_BLOCKED_BY"
          - task_title: "Implement Live UI Updates via WebSockets"
            type: "IS_BLOCKED_BY"
      - title: "Write E2E Tests for Field Mode UI"
        summary: "Create end-to-end tests to verify the functionality and readability of the new field mode interface."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Integrate Field Mode with Live UI Updates"
            type: "IS_BLOCKED_BY"
      - title: "Run Pre-Commit Checks on Field Mode Code"
        summary: "Run pre-commit hooks on all new field mode-related code."
        status: "pending"
        priority: "high"
        complexity: 1
        dependencies:
          - task_title: "Write E2E Tests for Field Mode UI"
            type: "IS_BLOCKED_BY"

  - name: "MQTT Integration for IoT"
    summary: "Implement support for publishing detection events to an MQTT broker for seamless integration with Home Assistant and other IoT platforms."
    tags: [ "integrations" ]
    templates:
      - "Requirements Specification"
    sections:
      - title: "Must-Have Requirements"
        format: "MARKDOWN"
        content: |
          ## Must-Have Requirements

          ### Core Functionality
          1. **REQ-MQTT-001**: Publish Detection Events to MQTT
             - **Description**: The system must be able to connect to a user-configured MQTT broker and publish a message for each new bird detection that meets the confidence threshold.
             - **User Story**: As a Home Automator, I want the system to publish detection events to my MQTT broker so that I can trigger automations, such as turning on an outdoor camera or sending a custom notification.
             - **Acceptance Criteria**:
               - Given a valid MQTT broker is configured and a bird is detected, then a JSON payload containing the detection details (species, confidence, timestamp) must be published to the configured MQTT topic.
               - Given the MQTT broker is unavailable, then the system must log the connection error and continue operating without crashing.
             - **Priority**: Critical

          ### Data Requirements
          - **Data Output**: A structured JSON message for each detection event. The payload should be well-documented and consistent. Example: `{"species": "American Robin", "confidence": 0.91, "timestamp": "2025-07-22T14:52:00Z"}`

          ### Integration Requirements
          - **Internal System Integration**: The MQTT publishing logic must be triggered by the existing `DetectionEventPublisher` (Blinker signal) to ensure it is decoupled from the core analysis loop.

      - title: "Nice-to-Have Features"
        format: "MARKDOWN"
        content: |
          ## Nice-to-Have Features

          ### Enhanced Functionality
          - **MQTT Remote Control**: Allow the system to subscribe to a specific MQTT topic to receive commands (e.g., force a recording, change a setting).
          - **Customizable Payload**: Allow users to define the structure of the JSON payload using a template.

      - title: "Constraints & Limitations"
        format: "MARKDOWN"
        content: |
          ## Constraints & Limitations

          ### Technical Constraints
          - **Technology Stack**: The implementation must use the `paho-mqtt` Python library.
          - **External Dependencies**: Requires a user-provided, functional MQTT broker. The system is not responsible for hosting the broker itself.

          ### Security Requirements
          - **Authentication**: The system must support username/password authentication for connecting to the MQTT broker.

    tasks:
      - title: "Research and Select MQTT Client Library"
        summary: "Investigate and choose a robust Python library for MQTT communication, such as paho-mqtt."
        status: "pending"
        priority: "high"
        complexity: 1
        templates:
          - "Technical Approach"
        sections:
          - title: "Architecture Overview"
            format: "MARKDOWN"
            content: |
              ## Architecture Overview

              ### System Design
              This task is a research spike to validate the core library for the `MqttPublisher` service. The design is a simple client-server model where our application is the client and the user's MQTT broker is the server. The chosen library will be wrapped in our service to abstract its specific implementation details.

              ### Key Components
              - **`paho-mqtt` (or alternative)**: The client library that handles the MQTT protocol.
              - **`MqttPublisher` Service**: Our internal service that will use the client library.

              ### Technology Stack
              - **Language/Framework**: Python 3.11
          - title: "Key Dependencies"
            format: "MARKDOWN"
            content: |
              ## Key Dependencies

              ### External Libraries
              | Library | Version | Purpose | Justification |
              |---------|---------|---------|---------------|
              | paho-mqtt | ~1.6.1 | MQTT Client Communication | It is the most mature, widely-used, and feature-complete MQTT client for Python, maintained by the Eclipse Foundation. |

              ### External Services
              - **MQTT Broker**: The implementation will require a running MQTT broker (e.g., Mosquitto) for testing and validation.

          - title: "Implementation Strategy"
            format: "MARKDOWN"
            content: |
              ## Implementation Strategy

              ### Implementation Phases
              1. **Phase 1: Research**
                 - **Goal**: Confirm that `paho-mqtt` is the best choice.
                 - **Deliverables**: A brief summary of any viable alternatives and a final decision.
                 - **Duration**: < 1 story point.

              2. **Phase 2: Prototyping**
                 - **Goal**: Create a simple proof-of-concept script.
                 - **Deliverables**: A Python script that successfully connects to a test MQTT broker, publishes a message, and disconnects.
                 - **Duration**: < 1 story point.

              ### Risk Mitigation
              - **Technical Risks**: The chosen library might have complex dependencies or be poorly maintained.
              - **Mitigation Strategy**: The research phase will explicitly check the library's maintenance status, open issues, and dependency tree. `paho-mqtt` is a low-risk choice due to its long history and community support.
      - title: "Implement MqttPublisher Service"
        summary: "Create a new service `MqttPublisher` that connects to an MQTT broker and provides a method to publish messages to a topic."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Research and Select MQTT Client Library"
            type: "IS_BLOCKED_BY"
      - title: "Integrate MQTT with DetectionEventPublisher"
        summary: "Create a new subscriber that listens for detection events and calls the `MqttPublisher` service to send the detection data."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Implement MqttPublisher Service"
            type: "IS_BLOCKED_BY"
          - task_title: "Implement Real-time Detection Engine"
            type: "IS_BLOCKED_BY"
      - title: "Write Unit Tests for MQTT Integration"
        summary: "Create unit tests for the `MqttPublisher` service, using a mock MQTT broker to verify functionality."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Integrate MQTT with DetectionEventPublisher"
            type: "IS_BLOCKED_BY"
      - title: "Run Pre-Commit Checks on MQTT Code"
        summary: "Run pre-commit hooks on all new MQTT-related modules."
        status: "pending"
        priority: "high"
        complexity: 1
        dependencies:
          - task_title: "Write Unit Tests for MQTT Integration"
            type: "IS_BLOCKED_BY"

  - name: "ONNX Model Integration"
    summary: "Implement support for the ONNX model format to enhance cross-platform compatibility and performance."
    tags: [ "integrations", "machine-learning" ]
    templates:
      - "Requirements Specification"
    sections:
      - title: "Must-Have Requirements"
        format: "MARKDOWN"
        content: |
          ## Must-Have Requirements

          ### Core Functionality
          1. **REQ-ONNX-001**: TFLite to ONNX Conversion
             - **Description**: The system must provide a mechanism to convert the existing TensorFlow Lite (`.tflite`) models into the ONNX (`.onnx`) format.
             - **User Story**: As a developer, I need a reliable way to convert our models to ONNX so that we can leverage a single model format across all deployment targets.
             - **Acceptance Criteria**:
               - Given a valid `.tflite` model file, when the conversion script is run, then a valid `.onnx` model file must be produced.
               - The conversion process must be documented and repeatable.
             - **Priority**: Low

          2. **REQ-ONNX-002**: ONNX Model Inference
             - **Description**: The `AnalysisManager` must be able to load an ONNX model and perform inference on an audio chunk.
             - **User Story**: As a user, I want the system to be able to use ONNX models for analysis so that I can benefit from potential performance improvements and broader hardware support.
             - **Acceptance Criteria**:
               - Given a valid `.onnx` model is configured, when an audio chunk is processed, then the system must successfully perform inference and produce a valid detection result.
               - The system must be configurable to switch between using TFLite and ONNX models.
             - **Priority**: Low

          ### Data Requirements
          - **Data Input**: `.tflite` model files for conversion.
          - **Data Output**: `.onnx` model files.

      - title: "Nice-to-Have Features"
        format: "MARKDOWN"
        content: |
          ## Nice-to-Have Features

          ### Performance Enhancements
          - **Hardware Acceleration**: Investigate and implement support for hardware-specific execution providers in ONNX Runtime (e.g., CUDA, TensorRT) to maximize performance.

      - title: "Constraints & Limitations"
        format: "MARKDOWN"
        content: |
          ## Constraints & Limitations

          ### Technical Constraints
          - **Upstream Models**: The success of this feature is entirely dependent on the ability of the `tf2onnx` library to correctly convert the specific operations used in the upstream BirdNET models.

    tasks:
      - title: "Research ONNX Runtime Libraries"
        summary: "Evaluate Python ONNX runtime libraries (e.g., onnxruntime) for performance and compatibility on both x86 and ARM architectures."
        status: "pending"
        priority: "low"
        complexity: 2
        templates:
          - "Technical Approach"
        sections:
          - title: "Architecture Overview"
            format: "MARKDOWN"
            content: |
              ## Architecture Overview

              ### System Design
              This task is a research spike to validate the core libraries for ONNX integration. The goal is to confirm the suitability of `onnxruntime` for our target platforms (x86 Docker, ARM SBCs) and `tf2onnx` for the model conversion process. The output will be a decision record and a simple proof-of-concept.

              ### Key Components
              - **`onnxruntime`**: The library for running inference.
              - **`tf2onnx`**: The library for model conversion.

              ### Technology Stack
              - **Language/Framework**: Python 3.11
          - title: "Key Dependencies"
            format: "MARKDOWN"
            content: |
              ## Key Dependencies

              ### External Libraries
              | Library | Version | Purpose | Justification |
              |---------|---------|---------|---------------|
              | onnxruntime | ~1.12.0 | ONNX Model Inference | The official, high-performance runtime for ONNX models, maintained by Microsoft. |
              | tf2onnx | ~1.9.3 | TFLite to ONNX Conversion | The standard, community-supported tool for converting TensorFlow models to ONNX. |

          - title: "Implementation Strategy"
            format: "MARKDOWN"
            content: |
              ## Implementation Strategy

              ### Implementation Phases
              1. **Phase 1: Research & Validation**
                 - **Goal**: Confirm library compatibility and conversion success.
                 - **Deliverables**: A simple script that successfully converts a BirdNET TFLite model to ONNX and another script that loads the ONNX model and runs a sample inference.
                 - **Duration**: 2 story points.

              ### Risk Mitigation
              - **Technical Risks**: The primary risk is that the `tf2onnx` converter may not support all the specific operations (ops) used in the BirdNET TFLite model, leading to a failed or incorrect conversion.
              - **Mitigation Strategy**: This research task is the mitigation. By attempting the conversion upfront, we will know if this feature is feasible before investing significant development effort. If it fails, the feature will be put on hold until converter support improves.
      - title: "Implement TFLite-to-ONNX Model Converter"
        summary: "Develop a `ModelConverter` service or script that uses libraries like `tf2onnx` to convert the existing TensorFlow Lite models to the ONNX format."
        status: "pending"
        priority: "low"
        complexity: 3
        dependencies:
          - task_title: "Research ONNX Runtime Libraries"
            type: "IS_BLOCKED_BY"
      - title: "Update AnalysisManager for ONNX Models"
        summary: "Modify the `AnalysisManager` to load and run inference with ONNX models using the selected runtime library."
        status: "pending"
        priority: "low"
        complexity: 3
        dependencies:
          - task_title: "Implement TFLite-to-ONNX Model Converter"
            type: "IS_BLOCKED_BY"
      - title: "Write Integration Tests for ONNX Inference"
        summary: "Create tests that load a converted ONNX model and verify that it produces the expected output for a sample audio file."
        status: "pending"
        priority: "low"
        complexity: 2
        dependencies:
          - task_title: "Update AnalysisManager for ONNX Models"
            type: "IS_BLOCKED_BY"
      - title: "Run Pre-Commit Checks on ONNX Code"
        summary: "Run pre-commit hooks on all new ONNX-related modules."
        status: "pending"
        priority: "low"
        complexity: 1
        dependencies:
          - task_title: "Write Integration Tests for ONNX Inference"
            type: "IS_BLOCKED_BY"
  - name: "Docker Deployment"
    summary: "Create and manage a containerized deployment of the application using Docker and Docker Compose."
    tags: [ "deployment" ]
    templates:
      - "Requirements Specification"
    sections:
      - title: "Must-Have Requirements"
        format: "MARKDOWN"
        content: |
          ## Must-Have Requirements

          ### Core Functionality
          1. **REQ-DOCKER-001**: Multi-Stage Dockerfile
             - **Description**: The system must provide a `Dockerfile` that builds a production-ready, multi-stage container image to ensure a small final image size and a clean build environment.
             - **User Story**: As a developer, I want a multi-stage Dockerfile so that I can create optimized, lightweight container images for efficient deployment.
             - **Acceptance Criteria**:
               - Given the `docker build` command is run, it must produce a valid container image without errors.
               - The final image must contain the Python application, all its dependencies, and the Caddy web server.
               - Build artifacts and development dependencies must not be present in the final image.
             - **Priority**: Critical

          2. **REQ-DOCKER-002**: Process Management with Supervisord
             - **Description**: The Docker container must use `supervisord` to manage all long-running processes, including the FastAPI/Uvicorn application and the Caddy server.
             - **User Story**: As an administrator, I want the container to use a robust process manager so that all necessary services start automatically and are restarted if they fail.
             - **Acceptance Criteria**:
               - When the container starts, `supervisord` must be the main process.
               - `supervisord` must successfully start both the `uvicorn` and `caddy` processes.
               - If either the `uvicorn` or `caddy` process terminates unexpectedly, `supervisord` must automatically restart it.
             - **Priority**: Critical

          ### Integration Requirements
          - **Data Persistence**: The Docker deployment must use volumes to persist the SQLite database, configuration files, and audio recordings outside the container.

      - title: "Nice-to-Have Features"
        format: "MARKDOWN"
        content: |
          ## Nice-to-Have Features

          ### Enhanced Functionality
          - **Multi-Arch Builds**: Create a build pipeline that automatically builds and pushes Docker images for both `amd64` (for standard servers/desktops) and `arm64` (for Raspberry Pi and other SBCs) architectures.

      - title: "Constraints & Limitations"
        format: "MARKDOWN"
        content: |
          ## Constraints & Limitations

          ### Technical Constraints
          - **Base Image**: The Docker image must be based on a stable, well-supported Linux distribution (e.g., Debian Bullseye).
          - **System Tools**: The final image must contain `caddy` and `supervisor` as system dependencies.

    tasks:
      - title: "Create Dockerfile"
        summary: "Develop a multi-stage Dockerfile to build a lightweight, production-ready container image for the application."
        status: "pending"
        priority: "high"
        complexity: 3
        templates:
          - "Technical Approach"
        sections:
          - title: "Architecture Overview"
            format: "MARKDOWN"
            content: |
              ## Architecture Overview

              ### System Design
              The Dockerfile will use a multi-stage build approach. The first stage (`builder`) will install Python dependencies using `uv` to leverage caching. The final stage will copy the installed dependencies and the application source code into a clean, minimal base image. This ensures the final image is as small as possible and does not contain unnecessary build tools.

              ### Key Components
              - **Builder Stage**: Based on a full Python image, installs dependencies.
              - **Final Stage**: Based on a minimal Debian image, copies application code and dependencies. Installs Caddy and Supervisord.

              ### Technology Stack
              - **Containerization**: Docker
              - **Process Management**: Supervisord
              - **Web Server**: Caddy
          - title: "Key Dependencies"
            format: "MARKDOWN"
            content: |
              ## Key Dependencies

              ### External Libraries
              | Library | Version | Purpose | Justification |
              |---------|---------|---------|---------------|
              | uv | latest | Python package installation | Chosen for its high speed and efficient caching, which speeds up Docker builds. |

              ### System Dependencies
              - `supervisor`: To manage processes within the container.
              - `caddy`: To act as the reverse proxy.
              - `git`: Required in the builder stage to install some dependencies.

          - title: "Implementation Strategy"
            format: "MARKDOWN"
            content: |
              ## Implementation Strategy

              ### Implementation Phases
              1. **Phase 1: Builder Stage**
                 - **Goal**: Create a build environment and install all Python packages.
                 - **Deliverables**: A `Dockerfile` stage that copies `pyproject.toml` and uses `uv pip install` to create a virtual environment.

              2. **Phase 2: Final Stage**
                 - **Goal**: Create the lightweight production image.
                 - **Deliverables**: A `Dockerfile` stage that copies the virtual environment from the builder, copies the application source code, and installs `caddy` and `supervisor` via `apt`.

              3. **Phase 3: Configuration**
                 - **Goal**: Configure the container's entrypoint and default command.
                 - **Deliverables**: The `Dockerfile` will be configured to use `supervisord` as its `CMD`, pointing to the appropriate configuration file.
      - title: "Implement Supervisord for Process Management"
        summary: "Configure supervisord to manage the FastAPI/Uvicorn server and the Caddy reverse proxy within the container."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Create Dockerfile"
            type: "IS_BLOCKED_BY"
      - title: "Create Docker Compose Configuration"
        summary: "Develop a docker-compose.yml file for easy local development and deployment, defining services, volumes, and networks."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Implement Supervisord for Process Management"
            type: "IS_BLOCKED_BY"
      - title: "Write Integration Tests for Docker Deployment"
        summary: "Create a test suite that builds the Docker image and runs the container to verify that all services start correctly and are accessible."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Create Docker Compose Configuration"
            type: "IS_BLOCKED_BY"
      - title: "Run Pre-Commit Checks on Docker Files"
        summary: "Run pre-commit hooks (e.g., hadolint) on the Dockerfile and docker-compose.yml to ensure best practices."
        status: "pending"
        priority: "high"
        complexity: 1
        dependencies:
          - task_title: "Write Integration Tests for Docker Deployment"
            type: "IS_BLOCKED_BY"

  - name: "Embedded System / SBC Installation"
    summary: "Develop a robust installation process for bare-metal deployments on single-board computers like the Raspberry Pi."
    tags: [ "deployment", "sbc" ]
    templates:
      - "Requirements Specification"
    sections:
      - title: "Must-Have Requirements"
        format: "MARKDOWN"
        content: |
          ## Must-Have Requirements

          ### Core Functionality
          1. **REQ-INSTALL-001**: Foundational Environment Setup
             - **Description**: The installer must prepare the host operating system by installing all required system-level dependencies.
             - **User Story**: As a user, I want a single script that installs all necessary system packages so that I don't have to manually figure out the dependencies.
             - **Acceptance Criteria**:
               - Given a fresh OS image, when `install.sh` is run, then all required system packages (e.g., `git`, `python3`, `python3-venv`, `uv`) must be installed and available.
               - The script must successfully create a Python virtual environment for the application.
             - **Priority**: Critical

          2. **REQ-INSTALL-002**: Application-Specific Setup
             - **Description**: The installer must correctly configure the BirdNET-Pi application itself, including generating configuration files, setting up the database, and installing services.
             - **User Story**: As a user, I want the installer to automatically set up the application's configuration and database so that the system is ready to run immediately after installation.
             - **Acceptance Criteria**:
               - Given the foundational environment is set up, when `setup_app.py` is run, then a default `birdnet_pi_config.yaml` must be created.
               - The SQLite database file must be created and initialized with the correct schema.
               - `systemd` unit files for all core application services must be generated and installed into the correct system directory.
             - **Priority**: Critical

          3. **REQ-INSTALL-003**: Model File Download
             - **Description**: The installer must automatically download the required machine learning models from the project's GitHub Releases page.
             - **User Story**: As a user, I want the installer to automatically download the correct ML models so that I don't have to find and place them manually.
             - **Acceptance Criteria**:
               - Given the installer is run, when it completes, then the specified `.tflite` model files must be present in the application's `models/` directory.
             - **Priority**: Critical

      - title: "Constraints & Limitations"
        format: "MARKDOWN"
        content: |
          ## Constraints & Limitations

          ### Technical Constraints
          - **Operating System**: The installer must be designed to run on Debian-based Linux distributions (e.g., Raspberry Pi OS).
          - **System Tools**: The installer will rely on standard system utilities like `bash`, `apt`, `git`, and `systemd`.

    tasks:
      - title: "Create Main Bash Installer (install.sh)"
        summary: "Develop the main `install.sh` script to handle foundational environment setup, including system dependencies, Python installation, and virtual environment creation."
        status: "pending"
        priority: "high"
        complexity: 3
        templates:
          - "Technical Approach"
        sections:
          - title: "Architecture Overview"
            format: "MARKDOWN"
            content: |
              ## Architecture Overview

              ### System Design
              The installation process is a two-stage design. The primary `install.sh` script acts as a robust bootstrapper, responsible only for preparing the system environment. It then hands off control to a more powerful and flexible Python script, `setup_app.py`, for all application-specific logic. This separates system concerns from application concerns.

              ### Key Components
              - **`install.sh`**: A Bash script for system-level setup.
              - **`setup_app.py`**: A Python script for application-level configuration and installation.
              - **`SystemdManager`**: An internal Python class that will be used by `setup_app.py` to dynamically generate and install systemd service files.

              ### Technology Stack
              - **Scripting**: Bash, Python 3.11
              - **Package Management**: `apt` (system), `uv` (Python)
              - **Service Management**: `systemd`
          - title: "Key Dependencies"
            format: "MARKDOWN"
            content: |
              ## Key Dependencies

              ### System Dependencies
              - `git`: For cloning the application repository.
              - `python3`: The core runtime.
              - `python3-venv`: For creating isolated Python environments.
              - `uv`: The high-speed Python package installer.
              - `curl`: For downloading the installer script itself.

          - title: "Implementation Strategy"
            format: "MARKDOWN"
            content: |
              ## Implementation Strategy

              ### Implementation Phases
              1. **Phase 1: System Bootstrap (`install.sh`)**
                 - **Goal**: Prepare the host OS.
                 - **Deliverables**: A script that checks for and installs `git`, `python3`, `python3-venv`, and `uv`. It will then clone the repository and create/activate a virtual environment.

              2. **Phase 2: Application Setup (`setup_app.py` call)**
                 - **Goal**: Configure the application.
                 - **Deliverables**: The `install.sh` script will conclude by executing `python install/setup_app.py`.

              ### Risk Mitigation
              - **Technical Risks**: Different versions of Debian or Raspberry Pi OS may have different package names or require different setup steps.
              - **Mitigation Strategy**: The `install.sh` script will include checks for the OS version and use conditional logic to handle known differences. It will also exit gracefully with a clear error message if an unsupported OS is detected.
      - title: "Implement Python Application Installer (setup_app.py)"
        summary: "Create the `setup_app.py` script to handle application-specific setup, such as generating configurations, initializing the database, and setting up systemd services."
        status: "pending"
        priority: "high"
        complexity: 3
        dependencies:
          - task_title: "Create Main Bash Installer (install.sh)"
            type: "IS_BLOCKED_BY"
      - title: "Integrate Systemd Service Management"
        summary: "Add logic to `setup_app.py` to dynamically generate and install systemd unit files for the core application services."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Implement Python Application Installer (setup_app.py)"
            type: "IS_BLOCKED_BY"
      - title: "Implement Model File Download Logic"
        summary: "Add logic to `install.sh` to download the required machine learning models from GitHub Releases."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Create Main Bash Installer (install.sh)"
            type: "IS_BLOCKED_BY"
      - title: "Write E2E Tests for Installation Script"
        summary: "Develop an end-to-end testing process (manual or automated) to validate the entire installation script on a clean OS image."
        status: "pending"
        priority: "high"
        complexity: 3
        dependencies:
          - task_title: "Integrate Systemd Service Management"
            type: "IS_BLOCKED_BY"
          - task_title: "Implement Model File Download Logic"
            type: "IS_BLOCKED_BY"
      - title: "Run Pre-Commit Checks on Installer Scripts"
        summary: "Run pre-commit hooks (e.g., shellcheck) on all new and modified installer scripts."
        status: "pending"
        priority: "high"
        complexity: 1
        dependencies:
          - task_title: "Write E2E Tests for Installation Script"
            type: "IS_BLOCKED_BY"

  - name: "Hardware Status Monitoring"
    summary: "Implement active monitoring of connected hardware, such as audio input devices."
    tags: [ "field-mode", "system-administration" ]
    templates:
      - "Requirements Specification"
    sections:
      - title: "Must-Have Requirements"
        format: "MARKDOWN"
        content: |
          ## Must-Have Requirements

          ### Core Functionality
          1. **REQ-HSM-001**: Audio Device Disconnection Detection
             - **Description**: The system must actively monitor the connection status of the selected audio input device (microphone/soundcard).
             - **User Story**: As a Field User, I need to be immediately alerted if my microphone gets unplugged so that I don't unknowingly record silence and lose valuable data.
             - **Acceptance Criteria**:
               - Given a recording is in progress with a connected audio device, when the device is physically disconnected, then a "disconnected" event is triggered within the application.
               - Given the application starts without the configured audio device being present, then a "disconnected" event is triggered.
             - **Priority**: Critical

          2. **REQ-HSM-002**: User-Facing Notification
             - **Description**: When an audio device disconnection is detected, a clear and persistent visual notification must be presented to the user in the web interface.
             - **User Story**: As a Field User, I want a clear, unmissable warning on my screen when the microphone is not working so I can immediately fix the connection.
             - **Acceptance Criteria**:
               - Given a "disconnected" event is triggered, when a user is viewing the web interface, then a prominent status indicator (e.g., a red, flashing icon in the navbar) must appear.
               - Given the audio device is reconnected and the system detects it, then the visual warning must be removed.
             - **Priority**: Critical

          ### Integration Requirements
          - **API Requirements**: A WebSocket endpoint must be available for the frontend to receive real-time hardware status updates.
          - **Internal System Integration**: The monitoring logic must be integrated directly into the new pure Python Audio Pipeline. The pipeline will be the source of truth for the audio device's status.

          ### User Interface Requirements
          - **User Experience**: The status indicator must be placed in a globally visible area, such as the main navigation bar, and use color (red for error) and possibly an icon to clearly communicate the status.
          - **Accessibility**: The indicator should be accessible to screen readers, providing a text-based alert (e.g., "Warning: Audio device disconnected").

      - title: "Nice-to-Have Features"
        format: "MARKDOWN"
        content: |
          ## Nice-to-Have Features

          ### User Experience Enhancements
          - **Audible Alerts**: Play an audible warning sound in the browser in addition to the visual indicator to alert users who may not be looking at the screen.
          - **Periodic Re-check**: If a device is disconnected, the system could periodically attempt to re-establish the connection automatically and clear the warning if successful.

      - title: "Constraints & Limitations"
        format: "MARKDOWN"
        content: |
          ## Constraints & Limitations

          ### Technical Constraints
          - **Technology Stack**: The implementation must use the existing Python `sounddevice` library for audio I/O and FastAPI for WebSockets.
          - **Detection Method**: Relies on the `sounddevice` library and the underlying OS audio driver (PortAudio/ALSA) to raise an exception or error code upon device failure. The detection is reactive, not proactive.

          ### Performance Requirements
          - **Resource Usage**: The monitoring process must have a negligible impact on CPU and memory usage, as it will run continuously.

          ### Security Requirements
          - **Authentication**: The WebSocket endpoint for status updates should not require authentication, as it provides non-sensitive system status information.

    tasks:
      - title: "Integrate Hardware Monitoring into AudioPipeline"
        summary: "Add logic to the `AudioPipeline` service to detect errors during audio stream reading, which indicate a device disconnection."
        status: "pending"
        priority: "high"
        complexity: 2
        templates:
          - "Technical Approach"
        sections:
          - title: "Architecture Overview"
            format: "MARKDOWN"
            content: |
              ## Architecture Overview

              ### System Design
              The hardware monitoring will be integrated directly into the `AudioPipeline` service. This service is the only component that directly interacts with the audio hardware, making it the natural place to detect connection issues. The detection will be reactive, based on exceptions raised by the `sounddevice` library during stream operations.

              ### Key Components
              - **`AudioPipeline` Service**: The core audio capture service. It will be modified to include error handling for device disconnections.
              - **`sounddevice` Library**: The underlying audio library that provides the error signals.
              - **`HardwareStatusPublisher`**: A new component (or an extension of an existing publisher) that will broadcast the status change event.

              ### Design Patterns
              - **Observer Pattern**: The `AudioPipeline` will act as the subject, and the `HardwareStatusPublisher` will be an observer that reacts to state changes (device errors).

              ### Data Flow
              `Audio Device → sounddevice Library → AudioPipeline Service (Exception Caught) → HardwareStatusPublisher → WebSocket → Frontend UI`

              ### Integration Points
              - **Internal System**: The `AudioPipeline` service is the primary integration point.
              - **External System/Service**: None.

              ### Technology Stack
              - **Language/Framework**: Python 3.11
              - **Libraries/Dependencies**: `sounddevice`, `blinker` (for internal signaling)
          - title: "Key Dependencies"
            format: "MARKDOWN"
            content: |
              ## Key Dependencies

              ### External Libraries
              | Library | Version | Purpose | Justification |
              |---------|---------|---------|---------------|
              | sounddevice | ~0.4.1 | Audio I/O | Core library for interacting with PortAudio/ALSA. |
              | blinker | ~1.4 | In-process signaling | Used for decoupling the event publishing from the audio pipeline. |

              ### Internal Dependencies
              - **`AudioPipeline` Service**: This task directly modifies this existing service.

          - title: "Implementation Strategy"
            format: "MARKDOWN"
            content: |
              ## Implementation Strategy

              ### Implementation Phases
              1. **Phase 1: Error Detection**
                 - **Goal**: Reliably detect audio device disconnection.
                 - **Deliverables**: A try-except block within the `AudioPipeline`'s main audio reading loop that specifically catches exceptions related to device errors (e.g., `PortAudioError`).
                 - **Duration**: 1 story point.
                 - **Dependencies**: A functional `AudioPipeline` service.

              2. **Phase 2: Event Publishing**
                 - **Goal**: Broadcast the hardware status change to the rest of the application.
                 - **Deliverables**: When an error is caught, the `AudioPipeline` will call the `HardwareStatusPublisher` to send a "disconnected" event. It will also send a "connected" event when the stream is successfully (re)started.
                 - **Duration**: 1 story point.
                 - **Dependencies**: Phase 1.

              ### Technical Approach
              - **Code Organization**: All new logic will be contained within the `AudioPipeline` service in `src/birdnetpi/services/audio_pipeline.py`.
              - **Error Handling**: The core of this task is robust error handling. The implementation must specifically identify the exception types thrown by `sounddevice` on device failure and handle them gracefully without crashing the service.
              - **Logging and Monitoring**: The service will log a critical error message using the structured logger when a device disconnects and an info message when it reconnects.

              ### Risk Mitigation
              - **Technical Risks**: The specific exception raised by `sounddevice` may vary across different operating systems or hardware.
              - **Mitigation Strategy**: The implementation will include a broad exception handler initially, with detailed logging to capture the exact error types encountered on the target hardware (RPi 3B+, etc.). This will allow for refinement in subsequent patches.

              ### Alternative Approaches Considered
              - **Alternative 1**: A separate monitoring process that periodically polls the list of connected audio devices.
              - **Why Rejected**: Polling is less efficient and less "real-time" than reactive error handling. It adds unnecessary complexity and another process to manage. The most reliable way to know if a device is working is to try and use it.
        dependencies:
          - task_title: "Run Pre-Commit Checks on Audio Pipeline Modules"
            type: "IS_BLOCKED_BY"
      - title: "Implement Hardware Status Publisher"
        summary: "Create a new Blinker signal or WebSocket publisher that broadcasts hardware status events (e.g., 'audio_device_disconnected')."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Integrate Hardware Monitoring into AudioPipeline"
            type: "IS_BLOCKED_BY"
      - title: "Create Frontend Hardware Status Indicator"
        summary: "Implement a UI component (e.g., a status icon in the navbar) that listens for hardware status events and displays a clear visual warning to the user."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Implement Hardware Status Publisher"
            type: "IS_BLOCKED_BY"
      - title: "Write Integration Tests for Hardware Monitoring"
        summary: "Create tests that simulate a device disconnection and verify that the correct event is published and the UI is updated."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Create Frontend Hardware Status Indicator"
            type: "IS_BLOCKED_BY"
      - title: "Run Pre-Commit Checks on Hardware Monitoring Code"
        summary: "Run pre-commit hooks on all new hardware monitoring-related code."
        status: "pending"
        priority: "high"
        complexity: 1
        dependencies:
          - task_title: "Write Integration Tests for Hardware Monitoring"
            type: "IS_BLOCKED_BY"

  - name: "Simplified Field Mode UI"
    summary: "Design and implement a user interface optimized for small screens and mobile use."
    tags: [ "field-mode", "ui-ux" ]
    templates:
      - "Requirements Specification"
    sections:
      - title: "Must-Have Requirements"
        format: "MARKDOWN"
        content: |
          ## Must-Have Requirements

          ### Core Functionality
          1. **REQ-FMUI-001**: High-Contrast, Minimalist Layout
             - **Description**: The system must provide a dedicated web page with a UI theme optimized for high visibility on small screens, including monochrome OLED displays.
             - **User Story**: As a Field User, I need a simple, high-contrast display so that I can easily read detection information at a glance while in a vehicle or bright sunlight.
             - **Acceptance Criteria**:
               - Given a user navigates to the `/field` endpoint, the page must render using a CSS theme with a black background, large white/monochrome fonts, and touch-friendly button sizes.
               - Given a new detection is received via WebSocket, it must be added to the top of a simple, auto-scrolling list on the page.
             - **Priority**: Critical

          ### Data Requirements
          - **Data Input**: Real-time detection events received from the WebSocket. Each event must contain the species name and confidence score.

          ### User Interface Requirements
          - **User Experience**: The UI must be extremely simple, displaying only a list of detections (e.g., "American Robin - 0.88"). It should require zero user interaction to be useful.
          - **Accessibility**: The high-contrast theme and large font sizes are the primary accessibility requirements.
          - **Responsive Design**: The layout must be fluid and function correctly on screens with a width as small as 320 pixels.

      - title: "Nice-to-Have Features"
        format: "MARKDOWN"
        content: |
          ## Nice-to-Have Features

          ### User Experience Enhancements
          - **Confidence Threshold Slider**: Allow the user to adjust the minimum confidence score for a detection to be displayed on the field UI in real-time.
          - **Tap-to-Hear**: Allow a user to tap on a detection in the list to play the associated audio clip.

      - title: "Constraints & Limitations"
        format: "MARKDOWN"
        content: |
          ## Constraints & Limitations

          ### Technical Constraints
          - **Technology Stack**: Must be implemented using the existing FastAPI/Jinja2 backend and standard HTML/CSS/JavaScript for the frontend. No new frontend frameworks should be introduced.

          ### Performance Requirements
          - **Resource Usage**: The page must be lightweight and have minimal impact on the performance of the core audio analysis services running on the SBC.

    tasks:
      - title: "Design High-Contrast UI Theme"
        summary: "Create a new CSS theme specifically for field mode, focusing on high contrast, large fonts, and touch-friendly targets."
        status: "pending"
        priority: "high"
        complexity: 2
      - title: "Create Field Mode Jinja2 Template"
        summary: "Develop a new Jinja2 template that presents a simple, auto-scrolling list of recent detections and their confidence scores."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Design High-Contrast UI Theme"
            type: "IS_BLOCKED_BY"
      - title: "Implement Field Mode FastAPI Route"
        summary: "Create a new FastAPI route (e.g., /field) that renders the new field mode template."
        status: "pending"
        priority: "high"
        complexity: 1
        dependencies:
          - task_title: "Create Field Mode Jinja2 Template"
            type: "IS_BLOCKED_BY"
      - title: "Integrate Field Mode with Live UI Updates"
        summary: "Ensure the field mode page correctly connects to the WebSocket and displays new detections in real-time."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Implement Field Mode FastAPI Route"
            type: "IS_BLOCKED_BY"
          - task_title: "Implement Live UI Updates via WebSockets"
            type: "IS_BLOCKED_BY"
      - title: "Write E2E Tests for Field Mode UI"
        summary: "Create end-to-end tests to verify the functionality and readability of the new field mode interface."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Integrate Field Mode with Live UI Updates"
            type: "IS_BLOCKED_BY"
      - title: "Run Pre-Commit Checks on Field Mode Code"
        summary: "Run pre-commit hooks on all new field mode-related code."
        status: "pending"
        priority: "high"
        complexity: 1
        dependencies:
          - task_title: "Write E2E Tests for Field Mode UI"
            type: "IS_BLOCKED_BY"

  - name: "MQTT Integration for IoT"
    summary: "Implement support for publishing detection events to an MQTT broker for seamless integration with Home Assistant and other IoT platforms."
    tags: [ "integrations" ]
    templates:
      - "Requirements Specification"
    sections:
      - title: "Must-Have Requirements"
        format: "MARKDOWN"
        content: |
          ## Must-Have Requirements

          ### Core Functionality
          1. **REQ-MQTT-001**: Publish Detection Events to MQTT
             - **Description**: The system must be able to connect to a user-configured MQTT broker and publish a message for each new bird detection that meets the confidence threshold.
             - **User Story**: As a Home Automator, I want the system to publish detection events to my MQTT broker so that I can trigger automations, such as turning on an outdoor camera or sending a custom notification.
             - **Acceptance Criteria**:
               - Given a valid MQTT broker is configured and a bird is detected, then a JSON payload containing the detection details (species, confidence, timestamp) must be published to the configured MQTT topic.
               - Given the MQTT broker is unavailable, then the system must log the connection error and continue operating without crashing.
             - **Priority**: Critical

          ### Data Requirements
          - **Data Output**: A structured JSON message for each detection event. The payload should be well-documented and consistent. Example: `{"species": "American Robin", "confidence": 0.91, "timestamp": "2025-07-22T14:52:00Z"}`

          ### Integration Requirements
          - **Internal System Integration**: The MQTT publishing logic must be triggered by the existing `DetectionEventPublisher` (Blinker signal) to ensure it is decoupled from the core analysis loop.

      - title: "Nice-to-Have Features"
        format: "MARKDOWN"
        content: |
          ## Nice-to-Have Features

          ### Enhanced Functionality
          - **MQTT Remote Control**: Allow the system to subscribe to a specific MQTT topic to receive commands (e.g., force a recording, change a setting).
          - **Customizable Payload**: Allow users to define the structure of the JSON payload using a template.

      - title: "Constraints & Limitations"
        format: "MARKDOWN"
        content: |
          ## Constraints & Limitations

          ### Technical Constraints
          - **Technology Stack**: The implementation must use the `paho-mqtt` Python library.
          - **External Dependencies**: Requires a user-provided, functional MQTT broker. The system is not responsible for hosting the broker itself.

          ### Security Requirements
          - **Authentication**: The system must support username/password authentication for connecting to the MQTT broker.

    tasks:
      - title: "Research and Select MQTT Client Library"
        summary: "Investigate and choose a robust Python library for MQTT communication, such as paho-mqtt."
        status: "pending"
        priority: "high"
        complexity: 1
        templates:
          - "Technical Approach"
        sections:
          - title: "Architecture Overview"
            format: "MARKDOWN"
            content: |
              ## Architecture Overview

              ### System Design
              This task is a research spike to validate the core library for the `MqttPublisher` service. The design is a simple client-server model where our application is the client and the user's MQTT broker is the server. The chosen library will be wrapped in our service to abstract its specific implementation details.

              ### Key Components
              - **`paho-mqtt` (or alternative)**: The client library that handles the MQTT protocol.
              - **`MqttPublisher` Service**: Our internal service that will use the client library.

              ### Technology Stack
              - **Language/Framework**: Python 3.11
          - title: "Key Dependencies"
            format: "MARKDOWN"
            content: |
              ## Key Dependencies

              ### External Libraries
              | Library | Version | Purpose | Justification |
              |---------|---------|---------|---------------|
              | paho-mqtt | ~1.6.1 | MQTT Client Communication | It is the most mature, widely-used, and feature-complete MQTT client for Python, maintained by the Eclipse Foundation. |

              ### External Services
              - **MQTT Broker**: The implementation will require a running MQTT broker (e.g., Mosquitto) for testing and validation.

          - title: "Implementation Strategy"
            format: "MARKDOWN"
            content: |
              ## Implementation Strategy

              ### Implementation Phases
              1. **Phase 1: Research**
                 - **Goal**: Confirm that `paho-mqtt` is the best choice.
                 - **Deliverables**: A brief summary of any viable alternatives and a final decision.
                 - **Duration**: < 1 story point.

              2. **Phase 2: Prototyping**
                 - **Goal**: Create a simple proof-of-concept script.
                 - **Deliverables**: A Python script that successfully connects to a test MQTT broker, publishes a message, and disconnects.
                 - **Duration**: < 1 story point.

              ### Risk Mitigation
              - **Technical Risks**: The chosen library might have complex dependencies or be poorly maintained.
              - **Mitigation Strategy**: The research phase will explicitly check the library's maintenance status, open issues, and dependency tree. `paho-mqtt` is a low-risk choice due to its long history and community support.
      - title: "Implement MqttPublisher Service"
        summary: "Create a new service `MqttPublisher` that connects to an MQTT broker and provides a method to publish messages to a topic."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Research and Select MQTT Client Library"
            type: "IS_BLOCKED_BY"
      - title: "Integrate MQTT with DetectionEventPublisher"
        summary: "Create a new subscriber that listens for detection events and calls the `MqttPublisher` service to send the detection data."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Implement MqttPublisher Service"
            type: "IS_BLOCKED_BY"
          - task_title: "Implement Real-time Detection Engine"
            type: "IS_BLOCKED_BY"
      - title: "Write Unit Tests for MQTT Integration"
        summary: "Create unit tests for the `MqttPublisher` service, using a mock MQTT broker to verify functionality."
        status: "pending"
        priority: "high"
        complexity: 2
        dependencies:
          - task_title: "Integrate MQTT with DetectionEventPublisher"
            type: "IS_BLOCKED_BY"
      - title: "Run Pre-Commit Checks on MQTT Code"
        summary: "Run pre-commit hooks on all new MQTT-related modules."
        status: "pending"
        priority: "high"
        complexity: 1
        dependencies:
          - task_title: "Write Unit Tests for MQTT Integration"
            type: "IS_BLOCKED_BY"

  - name: "ONNX Model Integration"
    summary: "Implement support for the ONNX model format to enhance cross-platform compatibility and performance."
    tags: [ "integrations", "machine-learning" ]
    templates:
      - "Requirements Specification"
    sections:
      - title: "Must-Have Requirements"
        format: "MARKDOWN"
        content: |
          ## Must-Have Requirements

          ### Core Functionality
          1. **REQ-ONNX-001**: TFLite to ONNX Conversion
             - **Description**: The system must provide a mechanism to convert the existing TensorFlow Lite (`.tflite`) models into the ONNX (`.onnx`) format.
             - **User Story**: As a developer, I need a reliable way to convert our models to ONNX so that we can leverage a single model format across all deployment targets.
             - **Acceptance Criteria**:
               - Given a valid `.tflite` model file, when the conversion script is run, then a valid `.onnx` model file must be produced.
               - The conversion process must be documented and repeatable.
             - **Priority**: Low

          2. **REQ-ONNX-002**: ONNX Model Inference
             - **Description**: The `AnalysisManager` must be able to load an ONNX model and perform inference on an audio chunk.
             - **User Story**: As a user, I want the system to be able to use ONNX models for analysis so that I can benefit from potential performance improvements and broader hardware support.
             - **Acceptance Criteria**:
               - Given a valid `.onnx` model is configured, when an audio chunk is processed, then the system must successfully perform inference and produce a valid detection result.
               - The system must be configurable to switch between using TFLite and ONNX models.
             - **Priority**: Low

          ### Data Requirements
          - **Data Input**: `.tflite` model files for conversion.
          - **Data Output**: `.onnx` model files.

      - title: "Nice-to-Have Features"
        format: "MARKDOWN"
        content: |
          ## Nice-to-Have Features

          ### Performance Enhancements
          - **Hardware Acceleration**: Investigate and implement support for hardware-specific execution providers in ONNX Runtime (e.g., CUDA, TensorRT) to maximize performance.

      - title: "Constraints & Limitations"
        format: "MARKDOWN"
        content: |
          ## Constraints & Limitations

          ### Technical Constraints
          - **Upstream Models**: The success of this feature is entirely dependent on the ability of the `tf2onnx` library to correctly convert the specific operations used in the upstream BirdNET models.

    tasks:
      - title: "Research ONNX Runtime Libraries"
        summary: "Evaluate Python ONNX runtime libraries (e.g., onnxruntime) for performance and compatibility on both x86 and ARM architectures."
        status: "pending"
        priority: "low"
        complexity: 2
        templates:
          - "Technical Approach"
        sections:
          - title: "Architecture Overview"
            format: "MARKDOWN"
            content: |
              ## Architecture Overview

              ### System Design
              This task is a research spike to validate the core libraries for ONNX integration. The goal is to confirm the suitability of `onnxruntime` for our target platforms (x86 Docker, ARM SBCs) and `tf2onnx` for the model conversion process. The output will be a decision record and a simple proof-of-concept.

              ### Key Components
              - **`onnxruntime`**: The library for running inference.
              - **`tf2onnx`**: The library for model conversion.

              ### Technology Stack
              - **Language/Framework**: Python 3.11
          - title: "Key Dependencies"
            format: "MARKDOWN"
            content: |
              ## Key Dependencies

              ### External Libraries
              | Library | Version | Purpose | Justification |
              |---------|---------|---------|---------------|
              | onnxruntime | ~1.12.0 | ONNX Model Inference | The official, high-performance runtime for ONNX models, maintained by Microsoft. |
              | tf2onnx | ~1.9.3 | TFLite to ONNX Conversion | The standard, community-supported tool for converting TensorFlow models to ONNX. |

          - title: "Implementation Strategy"
            format: "MARKDOWN"
            content: |
              ## Implementation Strategy

              ### Implementation Phases
              1. **Phase 1: Research & Validation**
                 - **Goal**: Confirm library compatibility and conversion success.
                 - **Deliverables**: A simple script that successfully converts a BirdNET TFLite model to ONNX and another script that loads the ONNX model and runs a sample inference.
                 - **Duration**: 2 story points.

              ### Risk Mitigation
              - **Technical Risks**: The primary risk is that the `tf2onnx` converter may not support all the specific operations (ops) used in the BirdNET TFLite model, leading to a failed or incorrect conversion.
              - **Mitigation Strategy**: This research task is the mitigation. By attempting the conversion upfront, we will know if this feature is feasible before investing significant development effort. If it fails, the feature will be put on hold until converter support improves.
      - title: "Implement TFLite-to-ONNX Model Converter"
        summary: "Develop a `ModelConverter` service or script that uses libraries like `tf2onnx` to convert the existing TensorFlow Lite models to the ONNX format."
        status: "pending"
        priority: "low"
        complexity: 3
        dependencies:
          - task_title: "Research ONNX Runtime Libraries"
            type: "IS_BLOCKED_BY"
      - title: "Update AnalysisManager for ONNX Models"
        summary: "Modify the `AnalysisManager` to load and run inference with ONNX models using the selected runtime library."
        status: "pending"
        priority: "low"
        complexity: 3
        dependencies:
          - task_title: "Implement TFLite-to-ONNX Model Converter"
            type: "IS_BLOCKED_BY"
      - title: "Write Integration Tests for ONNX Inference"
        summary: "Create tests that load a converted ONNX model and verify that it produces the expected output for a sample audio file."
        status: "pending"
        priority: "low"
        complexity: 2
        dependencies:
          - task_title: "Update AnalysisManager for ONNX Models"
            type: "IS_BLOCKED_BY"
      - title: "Run Pre-Commit Checks on ONNX Code"
        summary: "Run pre-commit hooks on all new ONNX-related modules."
        status: "pending"
        priority: "low"
        complexity: 1
        dependencies:
          - task_title: "Write Integration Tests for ONNX Inference"
            type: "IS_BLOCKED_BY"
